{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the DataJoint Documentation","text":"<ul> <li>DataJoint Python <p>Open-source framework for defining, operating, and querying data pipelines</p> <p> Learn more</p> </li> </ul> <ul> <li>DataJoint Elements <p>Open-source implementation of data pipelines for neuroscience studies</p> <p> Learn more</p> </li> </ul> <ul> <li>DataJoint Platform <p>A cloud platform for automated analysis workflows. It relies on DataJoint     Python and DataJoint Elements.</p> <p> Learn    more | Sign-in</p> </li> </ul> <ul> <li>Project Showcase <p>Projects and research teams supported by DataJoint software</p> <p> Learn more</p> </li> </ul>"},{"location":"additional-resources/","title":"Additional Resources","text":"<p>A collection of additional open-source tools for building and operating scientific data pipelines.</p>"},{"location":"additional-resources/#apis","title":"APIs","text":"<ul> <li> DataJoint MATLAB <p>A MATLAB client for defining, operating, and querying data pipelines.</p> <p> Legacy docs |    Source code</p> </li> </ul> <ul> <li> DataJoint Pharus <p>A REST API server for interacting with DataJoint pipelines.</p> <p> Docs |    Source code</p> </li> </ul>"},{"location":"additional-resources/#web-applications","title":"Web Applications","text":"<ul> <li> DataJoint LabBook <p>A browser-based graphical user interface for data entry and navigation. </p> <p> Legacy    docs |    Source code</p> </li> </ul> <ul> <li> DataJoint SciViz <p>A framework for making low-code web apps for data visualization.</p> <p> Legacy docs |    Source code</p> </li> </ul>"},{"location":"additional-resources/#container-images","title":"Container Images","text":"<pre><code>graph\n  %% Give short names\n  dj[\"datajoint/datajoint\"]\n  base[\"datajoint/djbase\"]\n  lab[\"datajoint/djlab\"]\n  hub[\"datajoint/djlabhub\"]\n  test[\"datajoint/djtest\"]\n  conda3[\"datajoint/miniconda3\"]\n  mysql[\"datajoint/mysql\"]\n  %% Define connections\n  conda3 --&gt; base --&gt; test;\n  base --&gt; dj;\n  base --&gt; lab --&gt; hub;\n  %% Add all to class\n  class dj,base,lab,hub,test,conda3,mysql boxes;\n  classDef boxes stroke:#333; %% Grey stroke for class</code></pre> <ul> <li> datajoint/mysql <p>MySQL server configured to work with DataJoint.</p> <p> Docker    image |    Source code</p> </li> </ul> <ul> <li> datajoint/miniconda3 <p>Minimal Python Docker image with conda.</p> <p> Docker   image |    Legacy docs |    Source code</p> </li> </ul> <ul> <li> datajoint/djbase <p>Minimal base Docker image with DataJoint Python dependencies installed. </p> <p> Docker    image |    Legacy docs |    Source code</p> </li> </ul> <ul> <li> datajoint/djtest <p>Docker image for running tests related to DataJoint Python. </p> <p> Docker    image |    Legacy docs |    Source code</p> </li> </ul> <ul> <li> datajoint/datajoint <p>Official DataJoint Docker image.</p> <p> Docker   image |    Source code</p> </li> </ul> <ul> <li> datajoint/djlab <p>Docker image optimized for running a JupyterLab environment with DataJoint Python. </p> <p> Docker    image |    Legacy docs |    Source code</p> </li> </ul> <ul> <li> datajoint/djlabhub <p>Docker image optimized for deploying to JupyterHub a JupyterLab environment with    DataJoint Python. </p> <p> Docker    image |    Legacy docs |    Source code</p> </li> </ul>"},{"location":"support-events/","title":"Community Support &amp; Events","text":""},{"location":"support-events/#support","title":"Support","text":"<ul> <li>Email our team at support@datajoint.com</li> </ul> <ul> <li>DataJoint Slack</li> </ul> <ul> <li>GitHub issue on the relevant repository</li> </ul> <ul> <li>DataJoint.com for fully managed services</li> </ul>"},{"location":"support-events/#events","title":"Events","text":"<p>Find us at the following workshops and conferences!</p> <ul> <li>COSYNE - March 27-30, 2025</li> </ul> <ul> <li>BRAIN NeuroAI Workshop - November 12, 2024</li> </ul> <ul> <li>Society for Neuroscience 2024 -   October 5-9, 2024</li> </ul> <ul> <li>INCF Neuroinformatics Assembly - September   23-27, 2024</li> </ul> <ul> <li>ACCN</li> </ul> <ul> <li>Gladstone Institutes - Neuroscience Seminar -   June 13, 2024</li> </ul> <ul> <li>10th Annual NIH BRAIN Initiative Conference -   June 16-18, 2024</li> </ul> <ul> <li>BIO - June 3-6, 2024</li> </ul> <ul> <li>2024 NWB Developer Hackathon - April   17-19, 2024</li> </ul> <ul> <li>DataJoint SciOps Summit 2024 - April   15-17, 2024</li> </ul> <ul> <li>COSYNE - February 29 - March 3, 2024</li> </ul> <ul> <li>Kavli NDI - January 18,2024</li> </ul> <ul> <li>UCSF - January 12, 2024</li> </ul> <ul> <li>RESI - January 9-11, 2024</li> </ul> <ul> <li>Society for Neuroscience - November   11-15, 2023</li> </ul> <ul> <li>Harvard School of Medicine Workshop: Data Workflows for Neuroscience Teams-   October 17, 18 &amp; 20, 2023</li> </ul> <ul> <li>MIT ODIN Symposium - October 10-12, 2023</li> </ul> <ul> <li>HLTH 2023 - October 8-11, 2023</li> </ul> <ul> <li>INCF Short Course: Introduction to Neuroinformatics -   October 2-4, 2023</li> </ul> <ul> <li>INCF Neuroinformatics Assembly Workshop: Research Workflows for Collaborative Neuroscience -   September 18-20, 2023</li> </ul> <ul> <li>SciPy - July 12-14, 2023</li> </ul> <ul> <li>Cold Spring Harbor Laboratory Neural Data Science Course -   July 11-24, 2023</li> </ul> <ul> <li>Allen Institute Neuropixels and OpenScope Workshop - June 21-22, 2023</li> </ul> <ul> <li>NIH BRAIN Initiative meeting - June 12-13, 2023</li> </ul> <ul> <li>Northwestern University - June 9, 2023</li> </ul> <ul> <li>University of Bonn - March 22-23, 2023</li> </ul> <ul> <li>Tel Aviv University - March 19-20, 2023</li> </ul> <ul> <li>COSYNE - March 9-12, 2023</li> </ul> <ul> <li>Flatiron Institute CCN 2023 Workshop on Calcium &amp; Voltage Imaging Analysis -   January 29 - February 1, 2023</li> </ul> <ul> <li>Society for Neuroscience - November   12-16, 2022</li> </ul> <ul> <li>Senses in Motion Symposium - October 17, 2022</li> </ul> <ul> <li>NeuroDataReHack Hackathon -   October 3-5, 2022</li> </ul> <ul> <li> <p>Neuromatch Conference - September 27-28, 2022</p> <ul> <li>Recording:   Automated Pipeline for Pose Estimation</li> </ul> </li> </ul> <ul> <li>Neuropixels and OpenScope Workshop -   September 21-23, 2022</li> </ul> <ul> <li>INCF Assembly - September 12-16, 2022</li> </ul> <ul> <li>Research Workflows Workshop -   September 6-8, 2022</li> </ul> <ul> <li> <p>DataJoint Office Hours - August 24, 2022</p> <ul> <li>Recording: LabBook Deployment</li> <li>Recording:   Attaching Element DeepLabCut</li> </ul> </li> </ul> <ul> <li> <p>Neurodata Without Borders Hackathon User Days -   July 24-27, 2022</p> <ul> <li>Recording:   Integrating DataJoint Pipelines with NWB</li> </ul> </li> </ul> <ul> <li>NIH BRAIN Initiative -   June 21-22, 2022</li> </ul> <ul> <li> <p>DataJoint Office Hours - May 20, 2022</p> <ul> <li>Recording:   MATLAB/Python interoperability</li> </ul> </li> </ul> <ul> <li> <p>DataJoint Office Hours - April 27, 2022</p> <ul> <li>Filepath handling, <code>linking_module</code>, and <code>key</code> management in <code>make</code> functions.</li> </ul> </li> </ul> <ul> <li>UCL Neuropixels Course -   October 19, 2021</li> </ul> <ul> <li> <p>INCF Neuroinformatics Training Week - August 30 - September 2, 2021</p> <ul> <li>Recording: Scientific Workflows and DataJoint Basics</li> <li>Recording:   Scientific Workflows, and DataJoint Imported &amp; Computed Tables</li> <li>Recording: DataJoint Element Array Electrophysiology</li> <li>Recording:   Setup DataJoint Elements Development Environment</li> </ul> </li> </ul> <ul> <li> <p>NYU \u2018FAIR Thee Well\u2019 Symposium - August 9-10, 2021</p> <ul> <li>Recording:   Sessions 1-3</li> </ul> </li> </ul> <ul> <li>Neuromatch Academy - July 29, 2021<ul> <li>Recording: Session 1</li> <li>Recording: Session 2</li> </ul> </li> </ul>"},{"location":"about/about/","title":"About","text":"<p>DataJoint Elements, DataJoint documentation, and DataJoint Web GUIs and APIs are supported by the NIH grant NIH U24 NS116470 for disseminating open-source software for neuroscience research.</p> <p>The goal is to systematize and disseminate data pipeline designs from leading neuroscience projects using the DataJoint framework.</p>"},{"location":"about/about/#aim-1-datajoint-pipelines-for-neurophysiology","title":"Aim 1: DataJoint Pipelines for Neurophysiology","text":"<p>Extract and systematize essential design motifs from published DataJoint-based projects as a collection of simple modules.</p>"},{"location":"about/about/#aim-2-access-and-training-resources","title":"Aim 2: Access and Training Resources","text":"<p>Support a dedicated resource for accessing and using DataJoint Pipelines for Neurophysiology.</p>"},{"location":"about/citation/","title":"Citation Guidelines","text":"<p>When your work uses the DataJoint Python, MATLAB, or Elements framework, please cite the respective manuscripts and include their associated Research Resource Identifiers (RRIDs). Proper citation helps credit the contributors and supports the broader scientific community by highlighting the tools used in research.</p>"},{"location":"about/citation/#citing-datajoint-elements","title":"Citing DataJoint Elements","text":"<p>If your work utilizes DataJoint Elements, please cite the following manuscript:</p> <ul> <li>Manuscript: Yatsenko D, Nguyen T, Shen S, Gunalan K, Turner CA, Guzman R, Sasaki   M, Sitonic D, Reimer J, Walker EY, Tolias AS. DataJoint Elements: Data Workflows for   Neurophysiology. bioRxiv. 2021 Jan 1. doi: https://doi.org/10.1101/2021.03.30.437358</li> </ul> <ul> <li>RRID: RRID:SCR_021894</li> </ul> <p>You should also cite the DataJoint Core manuscript detailed below.</p>"},{"location":"about/citation/#citing-the-datajoint-relational-model","title":"Citing the DataJoint Relational Model","text":"<p>For any work relying on the DataJoint Relational Model, include the following citation:</p> <ul> <li>Manuscript: Yatsenko D, Walker EY, Tolias AS. DataJoint: A simpler relational data   model. arXiv:1807.11104. 2018 Jul 29. doi: https://doi.org/10.48550/arXiv.1807.11104</li> </ul> <ul> <li>RRID: RRID:SCR_014543</li> </ul>"},{"location":"about/citation/#citing-datajoint-python-and-matlab","title":"Citing DataJoint Python and MATLAB","text":"<p>For work using DataJoint Python or DataJoint MATLAB, cite the following manuscript:</p> <ul> <li>Manuscript: Yatsenko D, Reimer J, Ecker AS, Walker EY, Sinz F, Berens P,   Hoenselaar A, Cotton RJ, Siapas AS, Tolias AS. DataJoint: Managing big scientific data   using MATLAB or Python. bioRxiv. 2015 Jan 1:031658. doi:   https://doi.org/10.1101/031658</li> </ul> <ul> <li>RRID: RRID:SCR_014543</li> </ul>"},{"location":"about/citation/#citing-sciops-and-capability-maturity-model","title":"Citing SciOps and Capability Maturity Model","text":"<p>If your work references SciOps or the Capability Maturity Model for Data-Intensive Research, please use the following citation:</p> <ul> <li>Manuscript: Johnson EC, Nguyen TT, Dichter BK, Zappulla F, Kosma M, Gunalan K,   Halchenko YO, Neufeld SQ, Schirner M, Ritter P, Martone ME. SciOps: Achieving   Productivity and Reliability in Data-Intensive Research. arXiv preprint   arXiv:2401.00077v2. 2023 Dec 29.</li> </ul> <ul> <li>RRID: TBD</li> </ul>"},{"location":"about/citation/#why-cite-datajoint","title":"Why Cite DataJoint?","text":"<p>By citing DataJoint and its associated resources:</p> <p>You give credit to the authors and contributors who developed these tools.</p> <p>You help other researchers identify and use these tools effectively.</p> <p>You strengthen the visibility and impact of open-source tools in scientific research.</p> <p>For further questions or assistance with citations, please reach out to the DataJoint support team (support@datajoint.com).</p>"},{"location":"about/contribute/","title":"Contribution Guidelines","text":"<p>Thank you for your interest in contributing to DataJoint open-source software!</p> <p>These guidelines are designed to ensure smooth collaboration, high-quality contributions, and a welcoming environment for all contributors. Please take a moment to review this document in order to make the contribution process easy and effective for everyone involved.</p> <p>The principal maintainer of DataJoint and associated tools is the DataJoint company. The pronouns \u201cwe\u201d and \u201cus\u201d in this guideline refer to the principal maintainers. We invite reviews and contributions of the open-source software. We compiled these guidelines to make this work clear and efficient.</p>"},{"location":"about/contribute/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Community Engagement</li> <li>How to Contribute<ul> <li>Project Lists</li> <li>Prerequisites</li> <li>Reporting Bugs</li> <li>Proposing Features or Enhancements</li> <li>Submitting Pull Requests (PRs)</li> <li>Code Reviews</li> </ul> </li> <li>Releases</li> <li>Contribution Acknowledgment</li> </ul>"},{"location":"about/contribute/#community-engagement","title":"Community Engagement","text":"<p>For general questions, ideas, discussions or live debugging sessions, please join DataJoint Slack or Stack Overflow, but for direct technical issues should stay in <code>Github Issue</code> in the respective project's repository. Response times may vary depending on maintainer availability.</p> <ul> <li>For resolving bugs, errors, or general debugging help, please submit it through <code>Github Issue</code> in the respective repository.</li> <li>For live debugging, urgent help, or broader discussions, join the DataJoint Slack.</li> <li>For feature requests, please open an issue directly in the <code>Github Issue</code> of the respective repository providing sufficient details to facilitate discussion and prioritization.</li> </ul> <p>Back to Top</p>"},{"location":"about/contribute/#how-to-contribute","title":"How to Contribute","text":""},{"location":"about/contribute/#project-lists","title":"Project Lists","text":"<p>Actively maintained projects by DataJoint:</p> <ul> <li>DataJoint Enhancement Proposal - in progress</li> <li>DataJoint Specs</li> <li>DataJoint Docs<ul> <li>It is the landing page of DataJoint documentation.</li> <li>Each project has its own documentation in its repository.</li> <li>Please help us to improve our documentations, it's the easiest but most impactful way to contribute!</li> </ul> </li> <li>DataJoint Python</li> <li>DataJoint Elements</li> <li>datajoint/djlabhub-docker</li> <li>datajoint/nginx-docker</li> </ul> <p>Archived projects by DataJoint, but still open for community contributions:</p> <ul> <li>Datajoint MATLAB</li> <li>DataJoint Pharus</li> <li>DataJoint SciViz</li> <li>DataJoint LabBook</li> <li>Most of Docker images expect the ones listed above</li> </ul>"},{"location":"about/contribute/#prerequisites","title":"Prerequisites","text":"<ul> <li>Familiarize yourself with the project documentation and guidelines.</li> <li>Start with reading the repository's <code>README.md</code> and <code>CONTRIBUTION.md</code>. You should expect to find the following instructions for the respective project:     - Installation instructions.     - Development environment setup.     - Testing instructions.</li> </ul> <p>Please open an issue in the respective repository if any of those instructions in the documentations or <code>READMD.md</code> are unclear to you. Contributions to documentations are equivalently important to any code for the community, please help us to resolve any confusions in documentations.</p>"},{"location":"about/contribute/#reporting-bugs","title":"Reporting Bugs","text":"<p>Before you open up a new issue, please check <code>Github Issue</code> to see if there are any related open/closed issues or open/closed PRs to avoid duplicates. If not, please open a new issue with clearly description of your bug, including:</p> <ul> <li>Steps to reproduce (if applicable).</li> <li>Expected and actual outcomes.</li> <li>Any relevant error messages, logs, or screenshots.</li> <li>Include environment details (e.g., OS, pip, conda dependencies) to speed up troubleshooting.</li> </ul>"},{"location":"about/contribute/#proposing-features-or-enhancements","title":"Proposing Features or Enhancements","text":"<p>Before starting your significant work, open a <code>Github Issue</code> to discuss your proposal first. Please include:</p> <ul> <li>A clear problem statement.</li> <li>Proposed solution or feature details.</li> <li>Relevant examples or use cases.</li> </ul> <p>There will be a repository for DataJoint Enhancement Proposal to centralize all proposals, it is currently in progress.</p>"},{"location":"about/contribute/#submitting-pull-requests-prs","title":"Submitting Pull Requests (PRs)","text":"<p>In DataJoint, we use Forking Workflow to manage contributions to keep the main fork's branch management clean.</p> <ol> <li>Fork the repository to your own Github account and clone it to your local machine.     - Please remember to always sync your fork's main branch with the DataJoint repository's main branch before starting your work.     - In your own fork, we suggest you use Feature Branch Workflow to manage your branches in your own fork, just in case someone will work on multiple contributions at the same time.</li> <li>Create a descriptive feature/fix branch from your fork's main branch, e.g., <code>fix/typo-docs</code> or <code>feature/add-logging</code>.</li> <li>Optionally, but highly recommended to follow Conventional Commits to make commit messages easier to be searched and categorized: If you use VSCode, please install Conventional Commits extension, it will help you to edit your commit messages following the commit types for versioning:     - <code>fix</code>: Bug fixes.     - <code>feat</code>: New features.     - <code>docs</code>: Documentation updates.     - <code>Breaking changes</code>: Changes would break backward compatibility, may affect the existing users when they upgrade. Use ! after the type or add BREAKING CHANGE in the commit footer.     - <code>chore</code>: Like the name, it is a chore.     - Example, if you are not using the VSCode extension: <code>git commit -m \"fix(auth): resolve token expiration bug.\"</code></li> <li>Reference related issue(s) in your PR description (e.g., Closes #123).</li> <li>Cover new functionality or bug fixes with appropriate tests. Ensure all tests pass before submission. Typically as it relates to tests, this means:<ol> <li>No syntax errors</li> <li>No integration errors</li> <li>No style errors e.g. PEP8, etc.</li> <li>Similar or better code coverage</li> </ol> </li> <li>Additional documentation to reflect new feature or behavior introduced.</li> <li>Provide a detailed PR description explaining the changes and their impact.</li> <li>Submit the PR for review. Maintainers will also ensure that PR\u2019s have the appropriate assignment for reviewer.</li> </ol>"},{"location":"about/contribute/#code-reviews","title":"Code Reviews","text":"<p>A contributor should not approve or merge their own PR. A maintainer will review and approve the PR.</p> <p>Reviewer suggestions or feedback should not be directly committed to a branch on a contributor\u2019s fork. A less intrusive way to collaborate would be for the reviewer to PR to the contributor\u2019s fork/branch that is associated with the main PR currently in review.</p> <p>Expect constructive feedback from maintainers. Maintainers will review your PR and suggest changes or improvements. Be responsive to feedback and iterate as needed. Reviews focus on code quality and adherence to standards, and documentation and test coverage. Once approved, the PR will be merged.</p> <p>Back to Top</p>"},{"location":"about/contribute/#releases","title":"Releases","text":"<p>Releases follow the standard definition of semantic versioning. Meaning:</p> <p><code>MAJOR</code> . <code>MINOR</code> . <code>PATCH/MICRO</code></p> <ul> <li><code>MAJOR</code> version bump when breaking changes make backward incompatible.</li> </ul> <ul> <li><code>MINOR</code> version bump when added functionalities is backward compatible.</li> </ul> <ul> <li><code>PATCH/MICRO</code> version when included bug fixes are backward compatible.</li> </ul> <p>Backward Compatible means that the existing users can upgrade to the new version without any changes to their existing code.</p> <p>For DataJoint open-source projects, we have two ways of making a release at this moment since we are improving the release process, and we will eventually consolidate into one way:</p> <ul> <li>Datajoint Python release, the future direction:<ul> <li>We use <code>Github Label</code> and PR Labeler action to categorize each PR.</li> <li>Then we use Release Drafter to manually trigger a Github Actions workflow to make a draft release.</li> <li>Changelog will be provided by Github Compare URL at the end of the release note.</li> <li>Then we manually publish the draft release to trigger a release Github Actions workflow.</li> </ul> </li> <li>Others:<ul> <li>This process is very dependent on conventional commits and tagging.</li> <li>It will be triggered by pushing a new tag to the repository.</li> <li>It uses python-semantic-release to parse all the conventional commits for the release note and <code>CHANGELOG.md</code>.</li> </ul> </li> </ul> <p>We found the former resolver would work the best for our community since contributors are from different background, we do not want to require them to adopt conventional commits.</p> <p>Back to Top</p>"},{"location":"about/contribute/#contribution-acknowledgment","title":"Contribution Acknowledgment","text":"<p>We deeply appreciate every contribution! By adhering to these guidelines, you help maintain the quality, usability, and success of any DataJoint open-source software.</p> <p>For any questions, feel free to reach out via <code>Github Issue</code> in the specific repository, our Community Slack or contact <code>support@datajoint.com</code>.</p> <p>Thank you for your contributions!</p> <p>Back to Top</p>"},{"location":"about/datajoint-team/","title":"Team","text":"<p>The project is performed by DataJoint with Dimitri Yatsenko as Principal Investigator.</p>"},{"location":"about/datajoint-team/#scientists","title":"Scientists","text":"<ul> <li>Dimitri Yatsenko, PhD - PI &amp; Chief Science and Technology Officer</li> </ul> <ul> <li>Thinh Nguyen, PhD - SciOps Lead</li> <li>Kushal Bakshi, PhD - SciOps Engineer</li> <li>Milagros Mar\u00edn, PhD - SciOps Engineer</li> </ul>"},{"location":"about/datajoint-team/#engineers","title":"Engineers","text":"<ul> <li>Drew Yang - Data Systems Engineer</li> <li>Ethan Ho - Software Engineer</li> </ul>"},{"location":"about/datajoint-team/#past-contributors","title":"Past contributors","text":"<ul> <li>Edgar Y. Walker - System Architect, Data Scientist, Project Manager (from project   start to Jan, 2021)</li> <li>Andreas S. Tolias - Grant proposal contributor</li> <li>Jacob Reimer - Grant proposal contributor</li> <li>Shan Shen - Data Scientist</li> <li>Joseph Burling - Data Scientist</li> <li>Chris Brozdowski - Data Scientist</li> <li>Tolga Dincer - Data Scientist</li> <li>Raphael Guzman - Software Engineer</li> <li>Maho Sasaki - Software Engineer</li> <li>Daniel Sitonic - Software Engineer</li> <li>Carlos Ortiz - Software Engineer</li> <li>Chetana Pitani - Software Engineer</li> <li>Christopher Turner - Data Systems Engineer</li> <li>Timothy Chandler - Data Systems Engineer</li> <li>David Godinez - Data Engineer</li> <li>Geetika Singh - Data Engineer</li> <li>Kabilar Gunalan - Project Manager, Data Scientist</li> <li>Jaerong Ahn - SciOps Engineer</li> <li>Jeroen Verswijver - Software Engineer</li> <li>Adib Baji - Software Engineer</li> <li>Sid Hulyalkar - SciOps Engineer</li> </ul> <p>The first-person pronouns \"we\" and \"our\" in these documents refer to those listed above.</p>"},{"location":"about/datajoint-team/#external-contributors","title":"External contributors","text":"<p>The principal components of the Resource are developed and distributed as open-source projects and external contributions are welcome. We have adopted a Contribution Guide for DataJoint, DataJoint Elements, and related open-source tools.</p>"},{"location":"about/history/","title":"History","text":"<p>Dimitri Yatsenko began development of DataJoint in Andreas S.Tolias' lab in the Neuroscience Department at Baylor College of Medicine in the fall of 2009. Initially implemented as a thin MySQL API in MATLAB, it defined the major principles of the DataJoint model.</p> <p>Many students and postdocs in the lab as well as collaborators and early adopters have contributed to the project. Jacob Reimer and Emmanouil Froudarakis became early adopters in Andreas Tolias' Lab and propelled development. Alexander S. Ecker, Philipp Berens, Andreas Hoenselaar, and R. James Cotton contributed to the formulation of the overall requirements for the data model and critical reviews of DataJoint development.</p> <p>Outside the Tolias lab, the first labs to adopt DataJoint (approx. 2010) were the labs of Athanassios G. Siapas at CalTech, Laura Busse and Steffen Katzner at the University of T\u00fcbingen.</p> <p>In 2015, the Python implementation gained momentum with Edgar Y. Walker and Fabian Sinz joining as principal contributors.</p> <p>In 2016, Andreas Tolias Lab joined the MICrONS project, using DataJoint to process volumes of neurophysiology and neuroanatomical data shared across large teams.</p> <p>In 2016, Vathes LLC was founded to provide support to groups using DataJoint.</p> <p>In 2017, DARPA awarded a small-business innovation research grant to Vathes LLC (Contract D17PC00162) to further develop and publicize the DataJoint framework.</p> <p>In June 2018, the Princeton Neuroscience Institute, under the leadership of Prof. Carlos Brody, began funding a project to generate a detailed DataJoint user manual.</p> <p>In 2022, DataJoint was awarded NIH grant NIH U24 NS116470 for disseminating open-source software for neuroscience research (Press Release).</p> <p>In 2025, Jim Olson, former executive at Flywheel, was appointed as the new CEO of DataJoint (Press Release).</p>"},{"location":"elements/","title":"DataJoint Elements for Neurophysiology","text":"<p>DataJoint Elements provides an efficient approach for neuroscience labs to create and manage scientific data workflows: the complex multi-step methods for data collection, preparation, processing, analysis, and modeling that researchers must perform in the course of an experimental study. Elements are a collection of curated modules for assembling workflows for several modalities of neurophysiology experiments and are designed for ease of integration into diverse custom workflows. This work is derived from the developments in leading neuroscience projects and uses the DataJoint API for defining, deploying, and sharing their data workflows.</p> <p>An overview of the principles of DataJoint workflows and the goals of DataJoint Elements are described in the position paper \"DataJoint Elements: Data Workflows for Neurophysiology\".</p> <p>Below are the projects that make up the family of open-source DataJoint Elements:</p> <ul> <li> Element Calcium Imaging <p>A data pipeline for calcium imaging microscopy.</p> <p> Interactive tutorial on GitHub   Codespaces</p> <p> Docs</p> </li> </ul> <ul> <li> Element Array Electrophysiology <p>A data pipeline for Neuropixels probes.</p> <p> Interactive tutorial on GitHub   Codespaces</p> <p> Docs</p> </li> </ul> <ul> <li> Element Electrode Localization <p>A data pipeline for electrode localization of Neuropixels probes.</p> <p> Docs</p> </li> </ul> <ul> <li> Element Miniscope <p>A data pipeline for miniscope calcium imaging.</p> <p> Interactive tutorial</p> <p> Docs</p> </li> </ul> <ul> <li> Element ZStack <p>A data pipeline for segmenting volumetric microscopy data with Cellpose, uploading   to BossDB, and visualizing with Neuroglancer.</p> <p> Interactive tutorial</p> <p> Docs</p> </li> </ul> <ul> <li> Element DeepLabCut <p>A data pipeline for pose estimation with DeepLabCut.</p> <p> Interactive tutorial on GitHub   Codespaces</p> <p> Docs</p> </li> </ul> <ul> <li> Element MoSeq <p>A data pipeline for motion sequencing with Keypoint-MoSeq.</p> <p> Interactive tutorial on GitHub   Codespaces</p> <p> Docs</p> </li> </ul> <ul> <li> Element Facemap <p>A data pipeline for pose estimation with Facemap.</p> <p> Docs</p> </li> </ul> <ul> <li> Element Optogenetics <p>A data pipeline for managing data from optogenetics experiments.</p> <p> Interactive tutorial on GitHub   Codespaces</p> <p> Docs</p> </li> </ul> <ul> <li> Element Visual Stimulus <p>A data pipeline for visual stimulation with Psychtoolbox.</p> <p> Docs</p> </li> </ul> <ul> <li> Element Lab <p>A data pipeline for lab management.</p> <p> Docs</p> </li> </ul> <ul> <li> Element Animal <p>A data pipeline for subject management.</p> <p> Docs</p> </li> </ul> <ul> <li> Element Session <p>A data pipeline for session management.</p> <p> Docs</p> </li> </ul> <ul> <li> Element Event <p>A data pipeline for event- and trial-based experiments.</p> <p> Docs</p> </li> </ul> <ul> <li> Element Interface <p>Common functions for the DataJoint Elements.</p> <p> Docs</p> </li> </ul>"},{"location":"elements/concepts/","title":"Concepts","text":"<p>The following conventions describe the DataJoint Python API implementation.</p>"},{"location":"elements/concepts/#datajoint-schemas","title":"DataJoint Schemas","text":"<p>The DataJoint Python API allows creating database schemas, which are namespaces for collections of related tables.</p> <p>The following commands declare a new schema and create the object named <code>schema</code> to reference the database schema.</p> PythonMatlab <pre><code>import datajoint as dj\nschema = dj.schema('&lt;schema_name&gt;')\n</code></pre> <p>We follow the convention of having only one schema defined per Python module. Then such a module becomes a DataJoint schema comprising a Python module with a corresponding database schema.</p> <p>The module's <code>schema</code> object is then used as the decorator for classes that define tables in the database.</p> <pre><code>dj.createSchema\n</code></pre> <p>In Matlab, we list one table per file and place schemas in folders.</p>"},{"location":"elements/concepts/#elements","title":"Elements","text":"<p>An Element is a software package defining one or more DataJoint schemas serving a particular purpose. By convention, such packages are hosted in individual GitHub repositories. For example, Element <code>element_calcium_imaging</code> is hosted at this GitHub repository and contains two DataJoint schemas: <code>scan</code> and <code>imaging</code>.</p>"},{"location":"elements/concepts/#youtube-tutorials","title":"YouTube Tutorials","text":"<p>The following YouTube videos provide information on basic design principles and file organization.</p> <ul> <li>Why neuroscientists should use relational databases   compared to traditional file hierarchies.</li> <li>Quickstart Guide including terminology,   and how to read DataJoint Diagrams and DataJoint Python table definitions.</li> <li>Intro to the Element and Workflow files   for an overview of the respective GitHub repositories.</li> <li>Overview of upstream Elements to ingest   and explore Lab, Animal, and Session metadata.<p>Some videos feature outdated versions of the respective GitHub repositories. For the   most updated information, check the   documentation page for the corresponding Element.</p> </li> </ul>"},{"location":"elements/concepts/#deferred-schemas","title":"Deferred schemas","text":"<p>A deferred schema is one in which the name of the database schema name is not specified. This module does not declare schema and tables upon import. Instead, they are declared by calling <code>schema.activate('&lt;schema_name&gt;')</code> after import.</p> <p>By convention, all modules corresponding to deferred schema must declare the function <code>activate</code> which in turn calls <code>schema.activate</code>.</p> <p>Thus, Element modules begin with:</p> <pre><code>import datajoint as dj\nschema = dj.schema()\n\ndef activate(schema_name):\nschema.activate(schema_name)\n</code></pre> <p>However, many activate functions perform other work associated with activating the schema such as activating other schemas upstream.</p>"},{"location":"elements/concepts/#linking-module","title":"Linking Module","text":"<p>To make the code more modular with fewer dependencies, Element modules do not <code>import</code> upstream schemas directly. Instead, all required classes and functions must be defined in a <code>linking_module</code> and passed to the module's <code>activate</code> function. By keeping all upstream requirements in the linking module, all Elements can be activated as part of any larger pipeline.</p> <p>For instance, the Scan module receives its required functions from the linking module passed into the module's <code>activate</code> function. See the example notebooks for an example of how the linking module is passed into the Element's module.</p>"},{"location":"elements/developer-guide/","title":"Developer instructions","text":""},{"location":"elements/developer-guide/#development-mode-installation","title":"Development mode installation","text":"<ul> <li>We recommend doing development work in a conda environment. For information on setting   up conda for the first time, see    this article.</li> </ul> <ul> <li>This method allows you to modify the source code for example DataJoint   workflows (e.g. <code>workflow-array-ephys</code>) and their   dependencies (e.g., <code>element-array-ephys</code>).</li> </ul> <ul> <li>Launch a new terminal and change directory to where you want to clone the   repositories (e.g., <code>bash cd ~/Projects</code>)</li> </ul> <ul> <li>Clone the relevant workflow and refer to the <code>requirements.txt</code> in the workflow for   the list of Elements to clone and install as editable. You will also need to install   <code>element-interface</code> <pre><code>deps=(\"lab\" \"animal\" \"session\" \"interface\" \"&lt;others&gt;\")\nfor repo in $deps # clone each\ndo \n    git clone https://github.com/datajoint/element-$repo\ndone\nfor repo in $(ls -d ./{element,workflow}*) # editable install \ndo \n    pip install -e ./$repo\ndone\n</code></pre> </li> </ul>"},{"location":"elements/developer-guide/#drop-schemas","title":"Drop schemas","text":"<p>If you need to drop all schemas to start fresh, you'll need to do following the dependency order. Refer to the workflow's notebook (<code>notebooks/06-drop-optional.ipynb</code>) for the drop order.</p>"},{"location":"elements/developer-guide/#pytests","title":"Pytests","text":"<ul> <li>Download the test dataset to your local machine. Note the directory where the dataset   is saved (e.g. <code>/tmp/testset</code>).</li> </ul> <ul> <li>Create an <code>.env</code> file within the <code>docker</code> directory with the following content.   Replace <code>/tmp/testset</code> with the directory where you have the test dataset downloaded.   <code>TEST_DATA_DIR=/tmp/testset</code></li> </ul> <ul> <li>If testing an unreleased version of the <code>element</code> or your fork of an <code>element</code> or the   <code>workflow</code>, within the <code>Dockerfile</code> uncomment the lines from the different options   presented. This will allow you to install the repositories of interest and run the   integration tests on those packages. Be sure that the <code>element</code> package version   matches the version in the <code>requirements.txt</code> of the <code>workflow</code>.</li> </ul> <ul> <li>Run the Docker container.   <pre><code>docker-compose -f ./docker/docker-compose-test.yaml up --build\n</code></pre></li> </ul>"},{"location":"elements/user-guide/","title":"User setup instructions","text":"<p>The following document describes how to setup a development environment and connect to a database so that you can use the DataJoint Elements to build and run a workflow on  your local machine. </p> <p>Any of the DataJoint Elements can be combined together to create a workflow that matches your experimental setup. We have a number of example workflows to get you started. Each focuses on a specific modality, but they can be adapted for your custom workflow. </p> <ol> <li> <p>Getting up and running will require a couple items for a good development   environment. If any of these items are already familiar to   you and installed on your machine, you can skip the corresponding section.</p> <p>1. Python</p> <p>2. Conda</p> <p>3. Integrated Development Environment</p> <p>4. Version Control (git)</p> <p>5. Visualization packages</p> </li> <li> <p>Next, you'll need to download one of the example workflows and    corresponding example data. </p> </li> <li> <p>Finally, there are a couple different approaches to   connecting to a database. Here, we highlight three approaches:</p> <p>1. First Time: Beginner. Temporary storage to learn the ropes.</p> <p>2. Local Database: Intermediate. Deployed on local hardware, managed        by you.</p> <p>3. Central Database: Advanced: Deployed on dedicated hardware.</p> </li> </ol>"},{"location":"elements/user-guide/#development-environment","title":"Development Environment","text":"<p>This diagram describes the general components for a local DataJoint environment. </p> <pre><code>flowchart LR\n  py_interp  --&gt;|DataJoint| db_server[(\"Database Server\\n(e.g., MySQL)\")]\n  subgraph conda[\"Conda environment\"]\n    direction TB\n    py_interp[Python Interpreter]\n  end\n  subgraph empty1[\" \"] %% Empty subgraphs prevent overlapping titles\n    direction TB\n    style empty1 fill:none, stroke-dasharray: 0 1\n    conda\n  end\n  subgraph term[\"Terminal or Jupyter Notebook\"]\n    direction TB\n    empty1\n  end\n  subgraph empty2[\" \"] %% Empty subgraphs prevent overlapping titles\n    direction TB\n    style empty2 fill:none, stroke-dasharray: 0 1\n    term\n  end\n  class py_interp,conda,term,ide,db_server,DataJoint boxes;\n  classDef boxes fill:#ddd, stroke:#333;</code></pre>"},{"location":"elements/user-guide/#python","title":"Python","text":"<p>DataJoint Elements are written in Python. The DataJoint Python API supports Python  versions 3.7 and up. We recommend downloading the latest stable release of 3.9 here, and following the install instructions. </p>"},{"location":"elements/user-guide/#conda","title":"Conda","text":"<p>Python projects each rely on different dependencies, which may conflict across projects. We recommend working in a Conda environment for each project to isolate the dependencies. For more information on why Conda, and setting up the version of Conda that best suits your needs, see  this article.</p> <p>To get going quickly, we recommend you ...</p> <ol> <li> <p>Download Miniconda and go through the setup, including adding Miniconda to your <code>PATH</code> (full   instructions    here).</p> </li> <li> <p>Declare and initialize a new conda environment with the following commands. Edit    <code>&lt;name&gt;</code> to reflect your project.</p> <pre><code>conda create --name datajoint-workflow-&lt;name&gt; python=3.9 \nconda activate datajoint-workflow-&lt;name&gt; \n</code></pre> </li> </ol> Apple M1 users: Click to expand <p>Running analyses with Element DeepLabCut or Element Calcium imaging may require tensorflow, which can cause issues on M1 machines. By saving the <code>yaml</code>  file below, this environment can be loaded with <code>conda create -f my-file.yaml </code>. If you encounter errors related to <code>clang</code>, try launching xcode  and retrying.</p> <pre><code>name: dj-workflow-&lt;name&gt;\nchannels:\n    - apple \n    - conda-forge\n    - defaults\ndependencies:\n    - tensorflow-deps\n    - opencv\n    - python=3.9\n    - pip&gt;=19.0 \n    - pip:\n        - tensorflow-macos\n        - tensorflow-metal\n        - datajoint\n</code></pre>"},{"location":"elements/user-guide/#integrated-development-environment-ide","title":"Integrated Development Environment (IDE)","text":"<p>Development and use can be done with a plain text editor in the terminal. However, an integrated development environment (IDE) can improve your experience. Several IDEs are available. We recommend  Microsoft's Visual Studio Code, also called  VS Code. To set up VS Code with Python for the first time, follow  this tutorial.</p>"},{"location":"elements/user-guide/#version-control-git","title":"Version Control (git)","text":"<p>Table definitions and analysis code can change over time, especially with multiple collaborators working on the same project. Git is an open-source, distributed version control system that helps keep track of what changes where made when, and by whom. GitHub is a platform that hosts projects managed with git. The example DataJoint Workflows are hosted on GitHub, we will use git to clone (i.e., download) this repository.</p> <ol> <li>Check if you already have git by typing <code>git --version</code> in a terminal window.</li> <li>If git is not installed on your system, please install git. </li> <li>You can read more about git basics here.</li> </ol>"},{"location":"elements/user-guide/#visualization-packages-jupyter-notebooks-datajoint-diagrams","title":"Visualization packages (Jupyter Notebooks, DataJoint Diagrams)","text":"<p>To run the demo notebooks and generate visualizations associated with an example workflow, you'll need a couple extra packages. </p> <p>Jupyter Notebooks help structure code (see here for full instructions on Jupyter within VS Code).</p> <ol> <li> <p>Install Jupyter packages     <pre><code>conda install jupyter ipykernel nb_conda_kernels\n</code></pre></p> </li> <li> <p>Ensure your VS Code python interpreter is set to your Conda environment path.</p> <p> Click to expand more details. <ul> <li>View &gt; Command Palette</li> <li>Type \"Python: Select Interpreter\", hit enter.</li> <li>If asked, select the workspace where you plan to download the workflow.</li> <li>If present, select your Conda environment. If not present, enter in the        path.</li> </ul> </p> </li> </ol> <p>DataJoint Diagrams rely on additional packages. To install these packages, enter the following command...     <pre><code>conda install graphviz python-graphviz pydotplus\n</code></pre></p>"},{"location":"elements/user-guide/#example-config-workflows-and-data","title":"Example Config, Workflows and Data","text":"<p>Of the options below, pick the workflow that best matches your  needs.</p> <ol> <li> <p>Change the directory to where you want to download the workflow.</p> <pre><code>cd ~/Projects\n</code></pre> </li> <li> <p>Clone the relevant repository, and change directories to this new directory.     <pre><code>git clone https://github.com/datajoint/&lt;repository&gt;\ncd &lt;repository&gt;\n</code></pre></p> </li> <li> <p>Install this directory as editable with the <code>-e</code> flag.     <pre><code>pip install -e .\n</code></pre> Why editable? Click for details         This lets you modify the code after installation and experiment with different         designs or adding additional tables. You may wish to edit <code>pipeline.py</code> or          <code>paths.py</code> to better suit your needs. If no modification is required,          using <code>pip install .</code> is sufficient.     </p> </li> <li> <p>Install <code>element-interface</code>, which has utilities used across different Elements and     Workflows.</p> <pre><code>pip install \"element-interface @ git+https://github.com/datajoint/element-interface\"\n</code></pre> </li> <li> <p>\u200bSet up a local DataJoint config file by saving the      following block as a json in your workflow directory as <code>dj_local_conf.json</code>. Not     sure what to put for the <code>&lt; &gt;</code> values below? We'll cover this when we      connect to the database</p> <pre><code>{\n    \"database.host\": \"&lt;hostname&gt;\",\n    \"database.user\": \"&lt;username&gt;\",\n    \"database.password\": \"&lt;password&gt;\",\n    \"loglevel\": \"INFO\",\n    \"safemode\": true,\n    \"display.limit\": 7,\n    \"display.width\": 14,\n    \"display.show_tuple_count\": true,\n    \"custom\": {\n        \"database.prefix\": \"&lt;username_&gt;\"\n    }\n}\n</code></pre> </li> </ol>"},{"location":"elements/user-guide/#example-workflows","title":"Example Workflows","text":"<ul> <li> Workflow Session <p>An example workflow for session management.</p> <p> Clone from GitHub</p> </li> </ul> <ul> <li> Workflow Array Electrophysiology <p>An example workflow for Neuropixels probes.</p> <p> Clone from GitHub</p> </li> </ul> <ul> <li> Workflow Calcium Imaging <p>An example workflow for calcium imaging microscopy.</p> <p> Clone from GitHub</p> </li> </ul> <ul> <li> Workflow Miniscope <p>An example workflow for miniscope calcium imaging.</p> <p> Clone from GitHub</p> </li> </ul> <ul> <li> Workflow DeepLabCut <p>An example workflow for pose estimation with DeepLabCut.</p> <p> Clone from GitHub</p> </li> </ul>"},{"location":"elements/user-guide/#example-data","title":"Example Data","text":"<p>The first notebook in each workflow will guide you through downloading example data from DataJoint's AWS storage archive. You can also process your own data. To use the  example data, you would ...</p> <ol> <li> <p>Install <code>djarchive-client</code></p> <pre><code>pip install git+https://github.com/datajoint/djarchive-client.git\n</code></pre> </li> <li> <p>Use a python terminal to import the <code>djarchive</code> client and view available datasets,     and revisions.</p> <pre><code>import djarchive_client\nclient = djarchive_client.client()\nlist(client.datasets())  # List available datasets, select one\nlist(client.revisions()) # List available revisions, select one\n</code></pre> </li> <li> <p>Prepare a directory to store the download data, for example in <code>/tmp</code>, then download    the data with the <code>djarchive</code> client. This may take some time with larger datasets.</p> <pre><code>import os\nos.makedirs('/tmp/example_data/', exist_ok=True)\nclient.download(\n    '&lt;workflow-dataset&gt;',\n    target_directory='/tmp/example_data',\n    revision='&lt;revision&gt;'\n)\n</code></pre> </li> </ol>"},{"location":"elements/user-guide/#example-data-organization","title":"Example Data Organization","text":"Array Ephys: Click to expand details <ul> <li>Dataset: workflow-array-ephys-benchmark</li> <li>Revision: 0.1.0a4</li> <li>Size: 293 GB</li> </ul> <p>The example <code>subject6/session1</code> data was recorded with SpikeGLX and processed with Kilosort2.  <pre><code>/tmp/example_data/\n- subject6\n- session1\n    - towersTask_g0_imec0\n    - towersTask_g0_t0_nidq.meta\n    - towersTask_g0_t0.nidq.bin\n</code></pre> Element and Workflow Array Ephys also support data recorded with  OpenEphys.</p> Calcium Imaging: Click to expand details <ul> <li>Dataset: workflow-array-calcium-imaging-test-set</li> <li>Revision: 0_1_0a2</li> <li>Size: 142 GB</li> </ul> <p>The example <code>subject3</code> data was recorded with Scanbox.  The example <code>subject7</code> data was recorded with ScanImage. Both datasets were processed with Suite2p. <pre><code>/tmp/example_data/\n- subject3/\n    - 210107_run00_orientation_8dir/\n        - run00_orientation_8dir_000_000.sbx\n        - run00_orientation_8dir_000_000.mat\n        - suite2p/\n            - combined\n            - plane0\n            - plane1\n            - plane2\n            - plane3\n- subject7/\n    - session1\n        - suite2p\n            - plane0\n</code></pre> Element and Workflow Calcium Imaging also support data collected with ... - Nikon - Prairie View - CaImAn</p> DeepLabCut: Click to expand details <ul> <li>Dataset: workflow-dlc-data</li> <li>Revision: v1</li> <li>Size: .3 GB</li> </ul> <p>The example data includes both training data and pretrained models. <pre><code>/tmp/test_data/from_top_tracking/\n- config.yml\n- dlc-models/iteration-0/from_top_trackingFeb23-trainset95shuffle1/\n    - test/pose_cfg.yaml\n    - train/\n        - checkpoint\n        - checkpoint_orig\n        \u2500 learning_stats.csv\n        \u2500 log.txt\n        \u2500 pose_cfg.yaml\n        \u2500 snapshot-10300.data-00000-of-00001\n        \u2500 snapshot-10300.index\n        \u2500 snapshot-10300.meta   # same for 103000\n- labeled-data/\n    - train1/\n        - CollectedData_DJ.csv\n        - CollectedData_DJ.h5\n        - img00674.png          # and others\n    - train2/                   # similar to above\n- videos/\n    - test.mp4\n    - train1.mp4\n</code></pre></p> FaceMap: Click to expand details <p>Associated workflow still under development</p> <ul> <li>Dataset: workflow-facemap</li> <li>Revision: 0.0.0</li> <li>Size: .3 GB</li> </ul>"},{"location":"elements/user-guide/#using-your-own-data","title":"Using Your Own Data","text":"<p>Some of the workflows carry some assumptions about how your file directory will be  organized, and how some files are named.</p> Array Ephys: Click to expand details <ul> <li> <p>In your DataJoint config, add another item under <code>custom</code>,      <code>ephys_root_data_dir</code>, for your local root data directory. This can include      multiple roots.</p> <pre><code>\"custom\": {\n    \"database.prefix\": \"&lt;username_&gt;\",\n    \"ephys_root_data_dir\": [\"/local/root/dir1\", \"/local/root/dir2\"]\n}\n</code></pre> </li> </ul> <ul> <li>The <code>subject</code> directory names must match the subject IDs in your subjects table.      The <code>ingest.py</code> script (     demo ingestion notebook     ) can help load these values from <code>./user_data/subjects.csv</code>.</li> </ul> <ul> <li>The <code>session</code> directories can have any naming convention, but must be specified      in the session table (see also     demo ingestion notebook     ). </li> </ul> <ul> <li>Each session can have multiple probes.</li> </ul> <ul> <li>The <code>probe</code> directory names must end in a one-digit number corresponding to the      probe number.</li> </ul> <ul> <li>Each <code>probe</code> directory should contain:     - One neuropixels meta file named <code>*[0-9].ap.meta</code>     - Optionally, one Kilosort output folder</li> </ul> <p>Folder structure: <pre><code>&lt;ephys_root_data_dir&gt;/\n\u2514\u2500\u2500\u2500&lt;subject1&gt;/                       # Subject name in `subjects.csv`\n\u2502   \u2514\u2500\u2500\u2500&lt;session0&gt;/                   # Session directory in `sessions.csv`\n\u2502   \u2502   \u2514\u2500\u2500\u2500imec0/\n\u2502   \u2502   \u2502   \u2502   *imec0.ap.meta\n\u2502   \u2502   \u2502   \u2514\u2500\u2500\u2500ksdir/\n\u2502   \u2502   \u2502       \u2502   spike_times.npy\n\u2502   \u2502   \u2502       \u2502   templates.npy\n\u2502   \u2502   \u2502       \u2502   ...\n\u2502   \u2502   \u2514\u2500\u2500\u2500imec1/\n\u2502   \u2502       \u2502   *imec1.ap.meta\n\u2502   \u2502       \u2514\u2500\u2500\u2500ksdir/\n\u2502   \u2502           \u2502   spike_times.npy\n\u2502   \u2502           \u2502   templates.npy\n\u2502   \u2502           \u2502   ...\n\u2502   \u2514\u2500\u2500\u2500&lt;session1&gt;/\n\u2502   \u2502   \u2502   ...\n\u2514\u2500\u2500\u2500&lt;subject2&gt;/\n\u2502   \u2502   ...\n</code></pre></p> Calcium Imaging: Click to expand details <p>Note: While Element Calcium Imaging can accommodate multiple scans per  session, Workflow Calcium Imaging assumes there is only one scan per session.</p> <ul> <li> <p>In your DataJoint config, add another item under <code>custom</code>,      <code>imaging_root_data_dir</code>, for your local root data directory. </p> <pre><code>\"custom\": {\n    \"database.prefix\": \"&lt;username_&gt;\",\n    \"imaging_root_data_dir\": \"/local/root/dir1\"\n}\n</code></pre> </li> </ul> <ul> <li>The <code>subject</code> directory names must match the subject IDs in your subjects table.      The <code>ingest.py</code> script (     tutorial notebook     ) can help load these values from <code>./user_data/subjects.csv</code>.</li> </ul> <ul> <li>The <code>session</code> directories can have any naming convention, but must be specified      in the session table (see also     [tutorial notebook])(https://github.com/datajoint/element-calcium-imaging/blob/main/notebooks/tutorial.ipynb)     . </li> </ul> <ul> <li>Each <code>session</code> directory should contain:     - All <code>.tif</code> or <code>.sbx</code> files for the scan, with any naming convention.     - One <code>suite2p</code> subfolder, containing the analysis outputs in the default naming          convention.     - One <code>caiman</code> subfolder, containing the analysis output <code>.hdf5</code> file, with any         naming convention.</li> </ul> <p>Folder structure: <pre><code>imaging_root_data_dir/\n\u2514\u2500\u2500\u2500&lt;subject1&gt;/                     # Subject name in `subjects.csv`\n\u2502   \u2514\u2500\u2500\u2500&lt;session0&gt;/                 # Session directory in `sessions.csv`\n\u2502   \u2502   \u2502   scan_0001.tif\n\u2502   \u2502   \u2502   scan_0002.tif\n\u2502   \u2502   \u2502   scan_0003.tif\n\u2502   \u2502   \u2502   ...\n\u2502   \u2502   \u2514\u2500\u2500\u2500suite2p/\n\u2502   \u2502       \u2502   ops1.npy\n\u2502   \u2502       \u2514\u2500\u2500\u2500plane0/\n\u2502   \u2502       \u2502   \u2502   ops.npy\n\u2502   \u2502       \u2502   \u2502   spks.npy\n\u2502   \u2502       \u2502   \u2502   stat.npy\n\u2502   \u2502       \u2502   \u2502   ...\n\u2502   \u2502       \u2514\u2500\u2500\u2500plane1/\n\u2502   \u2502           \u2502   ops.npy\n\u2502   \u2502           \u2502   spks.npy\n\u2502   \u2502           \u2502   stat.npy\n\u2502   \u2502           \u2502   ...\n\u2502   \u2502   \u2514\u2500\u2500\u2500caiman/\n\u2502   \u2502       \u2502   analysis_results.hdf5\n\u2502   \u2514\u2500\u2500\u2500&lt;session1&gt;/                 # Session directory in `sessions.csv`\n\u2502   \u2502   \u2502   scan_0001.tif\n\u2502   \u2502   \u2502   scan_0002.tif\n\u2502   \u2502   \u2502   ...\n\u2514\u2500\u2500\u2500&lt;subject2&gt;/                     # Subject name in `subjects.csv`\n\u2502   \u2502   ...\n</code></pre></p> DeepLabCut: Click to expand details <p>Note: Element DeepLabCut assumes you've already used the DeepLabCut GUI to  set up your project and label your data. This can include multiple roots.</p> <ul> <li>In your DataJoint config, add another item under      <code>custom</code>, <code>dlc_root_data_dir</code>, for your local root      data directory.     <pre><code>\"custom\": {\n    \"database.prefix\": \"&lt;username_&gt;\",\n    \"dlc_root_data_dir\": [\"/local/root/dir1\", \"/local/root/dir2\"]\n}\n</code></pre></li> </ul> <ul> <li>You have preserved the default DeepLabCut project directory, shown below.</li> </ul> <ul> <li>The paths in your various <code>yaml</code> files reflect the current folder structure.</li> </ul> <ul> <li>You have generated the <code>pickle</code> and <code>mat</code> training files. If not, follow the      DeepLabCut guide to      create a training dataset</li> </ul> <p>Folder structure: <pre><code>/dlc_root_data_dir/your_project/\n- config.yaml                   # Including correct path information\n- dlc-models/iteration-*/your_project_date-trainset*shuffle*/\n    - test/pose_cfg.yaml        # Including correct path information\n    - train/pose_cfg.yaml       # Including correct path information\n- labeled-data/any_names/*{csv,h5,png}\n- training-datasets/iteration-*/UnaugmentedDataSet_your_project_date/\n    - your_project_*shuffle*.pickle\n    - your_project_scorer*shuffle*.mat\n- videos/any_names.mp4\n</code></pre></p> Miniscope: Click to expand details <ul> <li> <p>In your DataJoint config, add another item under <code>custom</code>,      <code>miniscope_root_data_dir</code>, for your local root data directory.</p> <pre><code>\"custom\": {\n    \"database.prefix\": \"&lt;username_&gt;\",\n    \"miniscope_root_data_dir\": \"/local/root/dir\"\n}\n</code></pre> </li> </ul>"},{"location":"elements/user-guide/#relational-databases","title":"Relational databases","text":"<p>DataJoint helps you connect to a database server from your programming environment  (i.e., Python or MATLAB), granting a number of benefits over traditional file hierarchies  (see YouTube Explainer). We offer two  options:</p> <ol> <li>The First Time beginner approach loads example data to a temporary existing     database, saving you setup time. But, because this data will be purged intermittently,    it should not be used in a true experiment.</li> <li>The Local Database intermediate approach will walk you through     setting up your own database on your own hardware. While easier to manage, it may be     difficult to expose this to outside collaborators.</li> <li>The Central Database advanced approach has the benefits of running on dedicated hardware, but may require significant IT expertise and infrastructure depending on your needs.</li> </ol>"},{"location":"elements/user-guide/#first-time","title":"First time","text":"<p>Temporary storage. Not for production use.</p> <ol> <li>Make an account at accounts.datajoint.io.</li> <li>In a workflow directory, make a config <code>json</code> file called    <code>dj_local_conf.json</code> using your DataJoint account information and     <code>tutorial-db.datajoint.io</code> as the host.     <pre><code>{\n    \"database.host\": \"tutorial-db.datajoint.io\",\n    \"database.user\": \"&lt;datajoint-username&gt;\",\n    \"database.password\": \"&lt;datajoint-password&gt;\",\n    \"loglevel\": \"INFO\",\n    \"safemode\": true,\n    \"display.limit\": 7,\n    \"display.width\": 14,\n    \"display.show_tuple_count\": true,\n    \"custom\": {\n    \"database.prefix\": \"&lt;datajoint-username_&gt;\"\n    }\n}\n</code></pre> Note: Your database prefix must begin with your username in order to have      permission to declare new tables.</li> <li>Launch a Python terminal and start interacting with the workflow.</li> </ol>"},{"location":"elements/user-guide/#local-database","title":"Local Database","text":"<ol> <li> <p>Install Docker.   Why Docker? Click for details.          Docker makes it easy to package a program, including the file system and related          code libraries, in a container. This container can be distributed to any          machine, both automating and standardizing the setup process.     </p> </li> <li> <p>Test that docker has been installed by running the following command:    <pre><code>docker run --rm hello-world\n</code></pre></p> </li> <li>Launch the DataJoint MySQL server with the following command:    <pre><code> docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=tutorial datajoint/mysql\n</code></pre> What's this doing? Click for details. <ul> <li>Download a container image called datajoint/mysql, which is pre-installed and          configured MySQL database with appropriate settings for use with DataJoint     </li> <li>Open up the port 3306 (MySQL default) on your computer so that your database          server can accept connections.     </li> <li>Set the password for the root database user to be tutorial, which are then used          in the config file.     </li> </ul> </li> <li>In a workflow directory, make a config <code>json</code> file called    <code>dj_local_conf.json</code> using the following details. The prefix can be set to any value.     <pre><code>{\n    \"database.host\": \"localhost\",\n    \"database.password\": \"tutorial\",\n    \"database.user\": \"root\",\n    \"database.port\": 3306,\n    \"loglevel\": \"INFO\",\n    \"safemode\": true,\n    \"display.limit\": 7,\n    \"display.width\": 14,\n    \"display.show_tuple_count\": true,\n    \"custom\": {\n        \"database.prefix\": \"neuro_\"\n    }\n}\n</code></pre></li> </ol> Already familiar with Docker? Click here for details. <p>This document is written to apply to all example workflows. Many have a docker  folder used by developers to set up both a database and a local environment for  integration tests. Simply <code>docker compose up</code> the relevant file and  <code>docker exec</code> into the relevant container.</p>"},{"location":"elements/user-guide/#central-database","title":"Central Database","text":"<p>To set up a database on dedicated hardware may require expertise to set up and maintain. DataJoint's MySQL Docker image project  provides all the information required to set up a dedicated database.</p>"},{"location":"elements/user-guide/#interacting-with-the-workflow","title":"Interacting with the Workflow","text":""},{"location":"elements/user-guide/#in-python","title":"In Python","text":"<ol> <li> <p>Connect to the database and import tables</p> <pre><code>from &lt;relevant-workflow&gt;.pipeline import *\n</code></pre> </li> <li> <p>View the declared tables. For a more in depth explanation of how to run the workflow     and explore the data, refer to the      Jupyter notebooks      in the workflow directory.      Array Ephys: Click to expand details <pre><code>subject.Subject()\nsession.Session()\nephys.ProbeInsertion()\nephys.EphysRecording()\nephys.Clustering()\nephys.Clustering.Unit()\n</code></pre> Calcium Imaging: Click to expand details <pre><code>subject.Subject()\nsession.Session()\nscan.Scan()\nscan.ScanInfo()\nimaging.ProcessingParamSet()\nimaging.ProcessingTask()\n</code></pre> DeepLabCut: Click to expand details <pre><code>subject.Subject()\nsession.Session()\ntrain.TrainingTask()\nmodel.VideoRecording.File()\nmodel.Model()\nmodel.PoseEstimation.BodyPartPosition()\n</code></pre> </p> </li> </ol>"},{"location":"elements/user-guide/#datajoint-labbook","title":"DataJoint LabBook","text":"<p>DataJoint LabBook is a graphical user interface to facilitate data entry for existing DataJoint tables.</p> <ul> <li>Labbook Website - If a database is public (e.g.,      <code>tutorial-db</code>) and you have access, you can view the contents here.</li> </ul> <ul> <li>DataJoint LabBook Documentation,      including prerequisites, installation, and running the application</li> </ul> <ul> <li>DataJoint LabBook GitHub Repository</li> </ul>"},{"location":"elements/management/adoption/","title":"Guidelines for Adoption","text":"<p>DataJoint Elements offer flexible options for adoption, enabling researchers to seamlessly integrate them into their workflows. Below are the available paths for adoption based on your expertise and needs for your experiments.</p>"},{"location":"elements/management/adoption/#independent-adoption","title":"Independent Adoption","text":"<p>DataJoint Elements are designed for independent users who have:</p> <ul> <li>Moderate software development skills.</li> <li>A solid understanding of DataJoint principles.</li> <li>Adequate IT expertise or support.</li> </ul> <p>If you are new to DataJoint, we recommend starting with these resources to build a strong foundation:</p>"},{"location":"elements/management/adoption/#1-online-training-tutorials","title":"1. Online Training Tutorials","text":"<p>Learn to set up your DataJoint pipeline with interactive tutorials hosted on GitHub Codespaces:</p> <ul> <li>DataJoint Tutorials Repository:   A comprehensive set of tutorials to get started with DataJoint Python, organized in   Jupyter notebooks.</li> </ul> <ul> <li>Element-Specific Interactive Tutorials: Explore detailed guides for designing and   interacting with specific Element pipelines:<ul> <li>DataJoint Element Array Ephys</li> <li>DataJoint Element Calcium Imaging</li> <li>DataJoint Element DeepLabCut</li> <li>DataJoint Element Facemap</li> <li>DataJoint Element MoSeq</li> <li>DataJoint Element Miniscope</li> <li>DataJoint Element Optogenetics</li> <li>DataJoint Element Zstack</li> <li>DataJoint Element Electrode Localization</li> <li>DataJoint Element Visual Stimulus</li> </ul> </li> </ul>"},{"location":"elements/management/adoption/#2-workshops","title":"2. Workshops","text":"<p>Participate in workshops and events (online or in person) to gain hands-on experience and practical knowledge for implementing DataJoint workflows effectively.</p>"},{"location":"elements/management/adoption/#adoption-with-support-from-datajoint","title":"Adoption with Support from DataJoint","text":"<p>For institutions and labs requiring additional assistance, the DataJoint team offers tailored support services, including:</p>"},{"location":"elements/management/adoption/#training","title":"Training","text":"<ul> <li>User Training: Guidance for end-users to effectively utilize workflows.</li> <li>Developer Training: Support for developers implementing or extending workflows.</li> </ul>"},{"location":"elements/management/adoption/#hosting-and-infrastructure","title":"Hosting and Infrastructure","text":"<ul> <li>Data and Computation Hosting:<ul> <li>On-premises setups for your institution or lab.</li> <li>Integration with your existing cloud accounts.</li> <li>Fully managed cloud hosting by DataJoint.</li> </ul> </li> </ul>"},{"location":"elements/management/adoption/#workflow-execution","title":"Workflow Execution","text":"<ul> <li>Configuration and Automation: Assistance with setting up and automating workflows.</li> <li>Fully Managed Services: Optional services to oversee workflow execution and   management entirely.</li> </ul>"},{"location":"elements/management/adoption/#interfaces","title":"Interfaces","text":"<ul> <li>Data Entry, Export, and Publishing: Streamlined interfaces to efficiently manage   and share your research data.</li> </ul>"},{"location":"elements/management/adoption/#subsidized-support","title":"Subsidized Support","text":"<p>Qualified research groups may be eligible for subsidized services through grant funding. Contact the DataJoint team to explore funding options and determine your eligibility.</p> <p>By choosing the adoption path that best suits your lab's expertise and requirements, you can leverage DataJoint Elements to optimize your research workflows. For additional information or assistance, please contact the DataJoint team at support@datajoint.com.</p>"},{"location":"elements/management/dissemination/","title":"Dissemination Plan","text":""},{"location":"elements/management/dissemination/#1-dissemination","title":"1. Dissemination","text":"<p>We conduct activities to disseminate Resource components for adoption in diverse neuroscience labs. These activities include</p> <ul> <li>A central website for the Resource.</li> <li>Conference talks, presentations, and workshops</li> <li>Publications in peer-reviewed journals</li> <li>White papers posted on internet resources and websites</li> <li>On-site workshops by invitation</li> <li>Remote workshops and webinars</li> <li>Online interactive tutorials hosted on GitHub Codespaces<ul> <li>DataJoint Tutorials</li> <li>DataJoint Element Array Ephys</li> <li>DataJoint Element Calcium Imaging</li> <li>DataJoint Element DeepLabCut</li> <li>DataJoint Element Facemap</li> <li>DataJoint Element MoSeq</li> <li>DataJoint Element Miniscope</li> <li>DataJoint Element Optogenetics</li> <li>DataJoint Element Zstack</li> <li>DataJoint Element Electrode Localization</li> <li>DataJoint Element Visual Stimulus</li> </ul> </li> </ul>"},{"location":"elements/management/dissemination/#2-community-survey","title":"2. Community Survey","text":"<p>In order to measure the effectiveness of the Resource, we conduct several activities to estimate the adoption and use of the Resource:</p> <ul> <li> <p>A citation mechanism for individual components of the Resource.</p> Resource RRID DataJoint Core RRID:SCR_014543 DataJoint Elements RRID:SCR_021894 </li> </ul> <ul> <li>GitHub forks and dependent repositories.</li> </ul> <ul> <li>A register for self-reporting for component adoption and use (see DataJoint Community Survey).</li> </ul>"},{"location":"elements/management/governance/","title":"Project Governance","text":""},{"location":"elements/management/governance/#funding","title":"Funding","text":"<p>This Resource is supported by the National Institute Of Neurological Disorders And Stroke of the National Institutes of Health (NIH) under Award Number U24NS116470. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</p>"},{"location":"elements/management/governance/#scientific-steering-group","title":"Scientific Steering Group","text":"<p>The project oversight and guidance is provided by the Scientific Steering Group comprising</p> <ul> <li>Mackenzie Mathis (EPFL)</li> <li>John Cunningham (Columbia U)</li> <li>Carlos Brody (Princeton U)</li> <li>Karel Svoboda (Allen Institute)</li> <li>Nick Steinmetz (U of Washington)</li> <li>Loren Frank (UCSF)</li> </ul>"},{"location":"elements/management/outreach/","title":"Outreach Plan","text":"<p>Broad engagement with the neuroscience community is essential for the optimization, integration, and adoption of the Resource components. To achieve this, we conduct five types of outreach activities, each requiring a tailored approach:</p>"},{"location":"elements/management/outreach/#1-precursor-projects","title":"1. Precursor Projects","text":"<p>As part of our Selection Process, a Precursor Project is required for any new experimental modality to be incorporated into DataJoint Elements.</p> <p>A Precursor Project involves the development of a DataJoint pipeline for specific experiments, either independently or in collaboration with our team. Our outreach activities for Precursor Projects include:</p> <ul> <li>Engaging Development Teams: Reaching out to teams developing DataJoint pipelines for   new experimental paradigms or modalities.</li> <li>Identifying Key Components: Collaborating with these teams to identify essential   design motifs, analysis tools, and related interfaces.</li> <li>Team Interviews: Conducting interviews the core team to understand their collaborative   culture, practices, and procedures.</li> <li>Code and Dissemination Review: Reviewing their open-source code and dissemination   plans to assess compatibility and adaptability.</li> <li>Continuous Collaboration: Staying in contact with the team throughout the Element   development process to incorporate their contributions, gather feedback, and evaluate   design tradeoffs.</li> </ul> <p>When the new Element is released, a full attribution is given to the Precursor Project, ensuring their contributions are recognized.</p> <p>Rationale: The Resource does not aim to create fundamentally new solutions for neurophysiology data acquisition and analysis. Instead, it systematizes and disseminates existing open-source tools already proven in leading research projects.</p>"},{"location":"elements/management/outreach/#2-tool-developers","title":"2. Tool Developers","text":"<p>DataJoint pipelines depend on a variety of analysis tools, atlases, data standards, archives, catalogs, and other neuroinformatics resources created and maintained by the broader scientific community. To ensure the long-term sustainability of the Resource, we reach out to the tool developers to establish shared sustainability roadmaps.</p>"},{"location":"elements/management/plan/","title":"Management Plan","text":"<p>DataJoint Elements has established a Resource Management Plan to select projects for development, to assure quality, and to disseminate its output as summarized in the figure below:</p> <p></p> <p>The following sections provide detailed information.</p> <ul> <li>Team</li> <li>Project Governance</li> <li>Project Selection Process</li> <li>Quality Assurance</li> <li>Contribution Guideline</li> <li>Outreach Plan</li> <li>Dissemination Plan</li> </ul>"},{"location":"elements/management/quality-assurance/","title":"Quality Assurance","text":"<p>DataJoint and DataJoint Elements serve as frameworks and starting points for numerous new projects, setting the standard for data architecture and software design quality. To ensure higher quality, the following policies have been adopted into the Software Development Life Cycle (SDLC).</p>"},{"location":"elements/management/quality-assurance/#coding-standards","title":"Coding Standards","text":"<p>When writing code, the following principles should be observed:</p> <ul> <li> <p>Style: Code should be written for clear readability. Uniform and consistent naming   conventions, module structures, and formatting requirements must be established across   all components of the project.</p> <ul> <li>Python's PEP8   standard offers clear guidances that can be applied to all languages.</li> </ul> <ul> <li>Python code should be formatted using the   black code formatter.</li> <li>The maximum line length should be 88 characters.</li> </ul> </li> </ul> <ul> <li>Maintenance Overhead: The size of the codebase should be considered to prevent   unnecessarily large or complex solutions. As the codebase grows, the effort to review   and maintain it increases. Therefore, the goal is to find a balance that prevents the   codebase from becoming too large while avoiding convoluted complexity.</li> </ul> <ul> <li>Performance: Performance issues should be avoided, controlled, or, properly   justified. Considerations like memory management, garbage collection, disk   reads/writes, and processing overhead must be addressed to ensure an efficient   solution.</li> </ul>"},{"location":"elements/management/quality-assurance/#automated-testing","title":"Automated Testing","text":"<p>All components and their revisions must include appropriate automated software testing to be considered for release. The core framework must undergo thorough performance evaluation and comprehensive integration testing.</p> <p>Testing generally includes:</p> <ul> <li>Syntax: Verify that the code base does not contain any syntax errors and will run   or compile successfully.</li> </ul> <ul> <li>Unit &amp; Integration: Verify that low-level, method-specific tests (unit tests) and   any tests related coordinated interface between methods (integration tests) pass   successfully. Typically, when bugs are patched or features are introduced, unit and   integration tests are added to ensure that the use-case intended to be satisfied is   accounted for. This helps us prevent any regression in functionality.</li> </ul> <ul> <li>Style: Verify that the code base adheres to style guides for optimal readability.</li> </ul> <ul> <li>Code Coverage: Verify that the code base has similar or better code coverage than   the last run.</li> </ul>"},{"location":"elements/management/quality-assurance/#code-reviews","title":"Code Reviews","text":"<p>When introducing new code to the code base, the following will be required for acceptance by DataJoint core team into the main code repository.</p> <ul> <li>Independence: Proposed changes should not directly alter the code base in the   review process. New changes should be applied separately on a copy of the code base   and proposed for review by the DataJoint core team. For example, apply changes on a   GitHub fork and open a pull request targeting the <code>main</code> branch once ready for review.</li> </ul> <ul> <li>Etiquette: An author who has requested for a code for review should not accept and   merge their own code to the code base. A reviewer should not commit any suggestions   directly to the authors proposed changes but rather should allow the author to review.</li> </ul> <ul> <li>Coding Standards: Ensure the above coding standards are respected.</li> </ul> <ul> <li>Summary: A description should be included that summarizes and highlights the   notable changes that are being proposed.</li> </ul> <ul> <li>Issue Reference: Any bugs or feature requests that have been filed in the issue   tracker that would be resolved by acceptance should be properly linked and referenced.</li> </ul> <ul> <li>Satisfy Automated Tests: All automated tests associated with the project will be   verified to be successful prior to acceptance.</li> </ul> <ul> <li>Documentation: Documentation should be included to reflect any new feature or   behavior introduced.</li> </ul> <ul> <li>Release Notes: Include necessary updates to the release notes or change log to   capture a summary of the patched bugs and new feature introduction. Proper linking   should be maintained to associated tickets in issue tracker and reviews.</li> </ul>"},{"location":"elements/management/quality-assurance/#release-process","title":"Release Process","text":"<p>Upon satisfactory adherence to the above Coding Standards, Automated Testing, and Code Reviews:</p> <ul> <li>The package version will be incremented following the standard definition of   Semantic Versioning with a <code>Major.Minor.Patch</code>   number.</li> </ul> <ul> <li>Updates will be merged into the base repository <code>main</code> branch.</li> </ul> <ul> <li>A new release will be made on PyPI.</li> </ul> <p>For external research teams that reach out to us, we will provide engineering support to help users adopt the updated software, collect feedback, and resolve issues following the processes described in the section below. If the updates require changes in the design of the database schema or formats, a process for data migration will be provided upon request.</p>"},{"location":"elements/management/quality-assurance/#user-feedback-issue-tracking","title":"User Feedback &amp; Issue Tracking","text":"<p>All components will be organized in GitHub repositories with guidelines for contribution, feedback, and issue submission to the issue tracker. For more information on the general policy around issue filing, tracking, and escalation, see the DataJoint Open-Source Contribute policy. For research groups that reach out to us, our team will work closely to collect feedback and resolve issues. Typically issues will be prioritized based on their criticality and impact. If new feature requirements become apparent, this may trigger the creation of a separate workflow or a major revision of an existing workflow.</p>"},{"location":"elements/management/selection/","title":"Project Selection Process","text":"<p>The project milestones are set annually by the team under the stewardship of the NIH programmatic staff and with the guidance of the project's Scientific Steering Group</p> <p>We have adopted the following general criteria for selecting and accepting new projects to be included in the Resource.</p> <ol> <li> <p>Open Precursor Projects</p> <p>At least one open-source DataJoint-based Precursor Project must exist for any new  experiment modality to be accepted for support as part of the Resource. The Precursor  Project team must be open to interviews to describe in detail their process for the  experiment workflow, tools, and interfaces.</p> <p>The Precursor Projects must provide sample data for testing during development and  for tutorials. The Precursor Projects will be acknowledged in the development of the  component.</p> <p>Rationale: This Resource does not aim to develop fundamentally new solutions for  neurophysiology data acquisition and analysis. Rather it seeks to systematize and  disseminate existing open-source tools proven in leading research projects.</p> </li> <li> <p>Impact</p> <p>New components proposed for support in the project must be shown to be in demand by a  substantial population or research groups, on the order of 100+ labs globally.</p> </li> <li> <p>Sustainability</p> <p>For all third-party tools or resources included in the proposed component, their  long-term maintenance roadmap must be established. When possible, we will contact the  developer team and work with them to establish a sustainability roadmap. If no such  roadmap can be established, alternative tools and resources must be identified as  replacement.</p> </li> </ol>"},{"location":"partnerships/dandi/","title":"Sustainability Roadmap between DataJoint Elements and DANDI Archive","text":""},{"location":"partnerships/dandi/#aim","title":"Aim","text":"<p>DataJoint Elements and The DANDI Archive (DANDI) are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems.</p>"},{"location":"partnerships/dandi/#projects-and-teams","title":"Projects and Teams","text":""},{"location":"partnerships/dandi/#datajoint","title":"DataJoint","text":"<p>DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of   open-source reference database schemas and analysis workflows for neurophysiology   experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an   open-source software framework. The project is funded by the NIH grant U24 NS116470   and led by Dr. Dimitri Yatsenko.</p> <p>The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com.</p>"},{"location":"partnerships/dandi/#distributed-archives-for-neurophysiology-data-integration-dandi","title":"Distributed Archives for Neurophysiology Data Integration (DANDI)","text":"<p>DANDI - https://dandiarchive.org \u2014 is an archive for neurophysiology data,  providing neuroscientists with a common platform to share, archive, and process data.  The project is funded by the NIH grant R24 MH117295 and led by Dr. Satrajit S. Ghosh  and Dr. Yaroslav O. Halchenko.</p> <p>The principal developers of DANDI are at the Massachusetts Institute of Technology,  Dartmouth College, Catalyst Neuro, and Kitware.</p>"},{"location":"partnerships/dandi/#general-principles","title":"General Principles","text":""},{"location":"partnerships/dandi/#no-obligation","title":"No obligation","text":"<p>The developers of the two ecosystems acknowledge that this roadmap document creates no  contractual relationship between them but they agree to work together in the spirit of  partnership to ensure that there is a united, visible, and responsive leadership and to  demonstrate administrative and managerial commitment to coordinate development and  communications.</p>"},{"location":"partnerships/dandi/#coordinated-development","title":"Coordinated Development","text":"<p>The two projects will coordinate their development approaches to ensure maximum interoperability. This includes:</p> <ul> <li>coordinated use of terminology and nomenclatures</li> <li>support for testing infrastructure: unit testing and integration testing</li> <li>a coordinated software release process and versioning</li> <li>coordinated resolution of issues arising from joint use of the two tools</li> </ul>"},{"location":"partnerships/dandi/#points-of-contact","title":"Points of Contact","text":"<p>To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability  of DataJoint Elements and DANDI.</p> <p>For 2022, the DataJoint Elements POC is Dr. Kushal Bakshi (kushal@datajoint.com)</p> <p>For 2022, the DANDI POC is Dr.Satrajit Ghosh (satra@mit.edu)</p>"},{"location":"partnerships/dandi/#annual-review","title":"Annual Review","text":"<p>To achieve the aims of coordinated development, the principal developers conduct a  joint annual review of this roadmap document to ensure that the two programs are well  integrated and not redundant. The contents and resolutions of the review will be made  publicly available.</p>"},{"location":"partnerships/dandi/#licensing","title":"Licensing","text":"<p>The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements and DANDI.</p>"},{"location":"partnerships/dandi/#development-roadmap","title":"Development Roadmap","text":"<ul> <li> Mechanism to upload to DANDI -    Element Interface DANDI module</li> </ul> <ul> <li> Documentation to upload to DANDI -    Jupyter notebook</li> </ul>"},{"location":"partnerships/facemap/","title":"Sustainability Roadmap between DataJoint Elements and Facemap","text":""},{"location":"partnerships/facemap/#aim","title":"Aim","text":"<p>DataJoint Elements and Facemap are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems.</p>"},{"location":"partnerships/facemap/#projects-and-teams","title":"Projects and Teams","text":""},{"location":"partnerships/facemap/#datajoint","title":"DataJoint","text":"<p>DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of   open-source reference database schemas and analysis workflows for neurophysiology   experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an   open-source software framework. The project is funded by the NIH grant U24 NS116470   and led by Dr. Dimitri Yatsenko.</p> <p>The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com.</p>"},{"location":"partnerships/facemap/#facemap","title":"Facemap","text":"<p>Facemap - https://github.com/MouseLand/facemap \u2014 is a pipeline for processing imaging data. The project is funded by HHMI Janelia Research Campus and led by Dr. Carsen Stringer and Atika Syeda.</p> <p>The principal developers of Facemap are at the Janelia Research Campus.</p>"},{"location":"partnerships/facemap/#general-principles","title":"General Principles","text":""},{"location":"partnerships/facemap/#no-obligation","title":"No obligation","text":"<p>The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications.</p>"},{"location":"partnerships/facemap/#coordinated-development","title":"Coordinated Development","text":"<p>The two projects will coordinate their development approaches to ensure maximum interoperability. This includes:</p> <ul> <li>coordinated use of terminology and nomenclatures</li> <li>support for testing infrastructure: unit testing and integration testing</li> <li>a coordinated software release process and versioning</li> <li>coordinated resolution of issues arising from joint use of the two tools</li> </ul>"},{"location":"partnerships/facemap/#points-of-contact","title":"Points of Contact","text":"<p>To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability  of DataJoint Elements and Facemap.</p> <p>For 2022, the DataJoint Elements POC is Dr. Kushal Bakshi (kushal@datajoint.com)</p> <p>For 2022, the Facemap POC is Dr. Carsen Stringer (stringerc@janelia.hhmi.org)</p>"},{"location":"partnerships/facemap/#annual-review","title":"Annual Review","text":"<p>To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available.</p>"},{"location":"partnerships/facemap/#licensing","title":"Licensing","text":"<p>The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements  and Facemap.</p>"},{"location":"partnerships/facemap/#development-roadmap","title":"Development Roadmap","text":"<ul> <li> Mechanism to import Facemap results -  Element Facemap</li> </ul> <ul> <li> Mechanism to run Facemap within DataJoint Elements -  Element Facemap</li> </ul> <ul> <li> Tutorials on running DataJoint Element with Facemap - Tutorial</li> </ul> <ul> <li> Tests to verify loading Facemap data</li> </ul> <ul> <li> Tests to verify running Facemap</li> </ul>"},{"location":"partnerships/facemap/#citation","title":"Citation","text":"<p>If you use Facemap please cite  Stringer, Pachitariu, et al., Science 2019 in your publications.</p>"},{"location":"partnerships/incf/","title":"International Neuroinformatics Coordinating Facility (INCF)","text":"<p>DataJoint is a company member of the INCF.</p> <p>In 2023, Dr. Milagros Mar\u00edn and Dr. Dimitri Yatsenko presented \"Research workflows for collaborative neuroscience\" at INCF Neuroinformatics Assembly.</p> <p>From 2023 to 2025, Dr. Milagros Mar\u00edn is a member of the INCF Council for Training, Science, and Infrastructure (CTSI) and the INCF Training and Education Committee (TEC).</p> <p>In 2024, Dr. Dimitri Yatsenko served as the Chair of the Industry Advisory Council for the INCF.</p> <p>In 2025, Dr. Milagros Mar\u00edn joined the Scientific Collaboration and Education Theme Team (Neuro Community).</p>"},{"location":"partnerships/nwb/","title":"Sustainability Roadmap between DataJoint Elements and Neurodata Without Borders","text":""},{"location":"partnerships/nwb/#aim","title":"Aim","text":"<p>DataJoint Elements and Neurodata Without Borders (NWB) are two neuroinformatics    initiatives in active development. The projects develop independently yet they have   complementary aims and overlapping user communities. This document establishes key   processes for coordinating development and communications in order to promote   integration and interoperability across the two ecosystems.</p>"},{"location":"partnerships/nwb/#projects-and-teams","title":"Projects and Teams","text":""},{"location":"partnerships/nwb/#datajoint","title":"DataJoint","text":"<p>DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of   open-source reference database schemas and analysis workflows for neurophysiology   experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an   open-source software framework. The project is funded by the NIH grant U24 NS116470   and led by Dr. Dimitri Yatsenko.</p> <p>The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com.</p>"},{"location":"partnerships/nwb/#neurodata-without-borders-nwb","title":"Neurodata without Borders (NWB)","text":"<p>NWB - https://www.nwb.org \u2014 is a data standard for neurophysiology, providing   neuroscientists with a common standard to share, archive, use, and build analysis   tools for neurophysiology data. The project is funded by the NIH grant U24 NS120057   and led by Dr. Oliver Rubel (Lawrence Berkeley National Laboratory) and Dr. Benjamin   Dichter (Catalyst Neuro).</p> <p>The principal developers of NWB are the Lawrence Berkeley National Laboratory and Catalyst Neuro.</p>"},{"location":"partnerships/nwb/#general-principles","title":"General Principles","text":""},{"location":"partnerships/nwb/#no-obligation","title":"No obligation","text":"<p>The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications.</p>"},{"location":"partnerships/nwb/#coordinated-development","title":"Coordinated Development","text":"<p>The two projects will coordinate their development approaches to ensure maximum interoperability. This includes:</p> <ul> <li>coordinated use of terminology and nomenclatures</li> <li>support for testing infrastructure: unit testing and integration testing</li> <li>a coordinated software release process and versioning</li> <li>coordinated resolution of issues arising from joint use of the two tools</li> </ul>"},{"location":"partnerships/nwb/#points-of-contact","title":"Points of Contact","text":"<p>To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability of DataJoint Elements and NWB.</p> <p>For 2022, the DataJoint Elements POC is Dr. Kushal Bakshi (kushal@datajoint.com)</p> <p>For 2022, the NWB POC is Dr. Ryan Ly (Lawrence Berkeley National Laboratory)</p>"},{"location":"partnerships/nwb/#annual-review","title":"Annual Review","text":"<p>To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available.</p>"},{"location":"partnerships/nwb/#licensing","title":"Licensing","text":"<p>The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements workflows and NWB utilities.</p>"},{"location":"partnerships/openephysgui/","title":"Sustainability Roadmap between DataJoint Elements and Open Ephys GUI","text":""},{"location":"partnerships/openephysgui/#aim","title":"Aim","text":"<p>DataJoint Elements and Open Ephys GUI are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems.</p>"},{"location":"partnerships/openephysgui/#projects-and-teams","title":"Projects and Teams","text":""},{"location":"partnerships/openephysgui/#datajoint","title":"DataJoint","text":"<p>DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of open-source reference database schemas and analysis workflows for neurophysiology experiments, supported by DataJoint Core \u2014 https://datajoint.com/docs/core/ \u2014 an open-source software framework. The project is funded by the NIH grant U24 NS116470 and led by Dr. Dimitri Yatsenko.</p> <p>The principal developer of DataJoint Elements and DataJoint Core is the company DataJoint \u2014 https://datajoint.com.</p>"},{"location":"partnerships/openephysgui/#open-ephys-gui","title":"Open Ephys GUI","text":"<p>Open Ephys GUI \u2014 https://open-ephys.org/gui \u2014 is an open-source, plugin-based application for processing, visualizing, and recording data from extracellular electrodes. The project is funded by the NIH grant U24 NS109043 and led by Dr. Josh Siegle.</p> <p>The principal developers of the Open Ephys GUI are at the Allen Institute.</p>"},{"location":"partnerships/openephysgui/#general-principles","title":"General Principles","text":""},{"location":"partnerships/openephysgui/#no-obligation","title":"No obligation","text":"<p>The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications.</p>"},{"location":"partnerships/openephysgui/#coordinated-development","title":"Coordinated Development","text":"<p>The two projects will coordinate their development approaches to ensure maximum interoperability. This includes:</p> <ul> <li>coordinated use of terminology and nomenclatures</li> <li>support for testing infrastructure</li> <li>a coordinated software release process and versioning</li> <li>coordinated resolution of issues arising from joint use of the two tools</li> </ul>"},{"location":"partnerships/openephysgui/#points-of-contact","title":"Points of Contact","text":"<p>To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability  of DataJoint Elements and Open Ephys GUI.</p> <p>For 2023, the DataJoint Elements POC is Dr. Thinh Nguyen (thinh@datajoint.com).</p> <p>For 2023, the Open Ephys GUI POC is Dr. Josh Siegle (joshs@alleninstitute.org).</p>"},{"location":"partnerships/openephysgui/#annual-review","title":"Annual Review","text":"<p>To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available.</p>"},{"location":"partnerships/openephysgui/#licensing","title":"Licensing","text":"<p>The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements and Open Ephys GUI.</p>"},{"location":"partnerships/openephysgui/#development-roadmap","title":"Development Roadmap","text":"<ul> <li> Mechanism to import data acquired with the Open Ephys GUI - DataJoint Element Array Ephys - Open Ephys module</li> </ul> <ul> <li> Tests to verify loading of Open Ephys data - Pytests</li> </ul> <ul> <li> The Open Ephys team will inform the DataJoint team about any software releases that include changes to the binary data format (ongoing).</li> </ul>"},{"location":"partnerships/openephysgui/#citation","title":"Citation","text":"<p>If you use this package, please cite the Open Ephys paper in your publications.</p>"},{"location":"partnerships/suite2p/","title":"Sustainability Roadmap between DataJoint Elements and Suite2p","text":""},{"location":"partnerships/suite2p/#aim","title":"Aim","text":"<p>DataJoint Elements and Suite2p are two neuroinformatics initiatives in active   development. The projects develop independently yet they have complementary aims and   overlapping user communities. This document establishes key processes for   coordinating development and communications in order to promote integration and   interoperability across the two ecosystems.</p>"},{"location":"partnerships/suite2p/#projects-and-teams","title":"Projects and Teams","text":""},{"location":"partnerships/suite2p/#datajoint","title":"DataJoint","text":"<p>DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of   open-source reference database schemas and analysis workflows for neurophysiology   experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an   open-source software framework. The project is funded by the NIH grant U24 NS116470   and led by Dr. Dimitri Yatsenko.</p> <p>The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com.</p>"},{"location":"partnerships/suite2p/#suite2p","title":"Suite2p","text":"<p>Suite2p \u2014 https://www.suite2p.org \u2014 is a pipeline for processing calcium imaging   data. The project is funded by HHMI Janelia Research Campus and led by Dr. Carsen   Stringer and Dr. Marius Pachitariu.</p> <p>The principal developers of Suite2p are at the Janelia Research Campus.</p>"},{"location":"partnerships/suite2p/#general-principles","title":"General Principles","text":""},{"location":"partnerships/suite2p/#no-obligation","title":"No obligation","text":"<p>The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications.</p>"},{"location":"partnerships/suite2p/#coordinated-development","title":"Coordinated Development","text":"<p>The two projects will coordinate their development approaches to ensure maximum interoperability. This includes:</p> <ul> <li>coordinated use of terminology and nomenclatures</li> <li>support for testing infrastructure: unit testing and integration testing</li> <li>a coordinated software release process and versioning</li> <li>coordinated resolution of issues arising from joint use of the two tools</li> </ul>"},{"location":"partnerships/suite2p/#points-of-contact","title":"Points of Contact","text":"<p>To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability  of DataJoint Elements and Suite2p.</p> <p>For 2022, the DataJoint Elements POC is Dr. Kushal Bakshi (kushal@datajoint.com)</p> <p>For 2022, the Suite2p POC is Dr. Carsen Stringer (stringerc@janelia.hhmi.org)</p>"},{"location":"partnerships/suite2p/#annual-review","title":"Annual Review","text":"<p>To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available.</p>"},{"location":"partnerships/suite2p/#licensing","title":"Licensing","text":"<p>The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements and Suite2p.</p>"},{"location":"partnerships/suite2p/#development-roadmap","title":"Development Roadmap","text":"<ul> <li> Mechanism to import Suite2p results -  Element Interface Suite2p module</li> </ul> <ul> <li> Mechanism to run Suite2p within DataJoint Element -  Element Calcium Imaging</li> </ul> <ul> <li> Tutorials on running DataJoint Element with Suite2p -  Element Calcium Imaging Jupyter notebooks</li> </ul> <ul> <li> Tests to verify loading Suite2p data -  Pytests</li> </ul> <ul> <li> Tests to verify running Suite2p -  Pytests</li> </ul>"},{"location":"partnerships/suite2p/#citation","title":"Citation","text":"<p>If you use Suite2p please cite  Pachitariu et al., bioRxiv 2017 in your publications.</p>"},{"location":"projects/","title":"Project Showcase","text":"<ul> <li>Select projects supported by DataJoint software <p> Catalog</p> </li> </ul> <ul> <li>Research teams supported by DataJoint software <p> Teams</p> </li> </ul> <ul> <li>Publications supported by DataJoint software <p> Publications</p> </li> </ul>"},{"location":"projects/publications/","title":"Publications","text":"<p>The following publications relied on DataJoint open-source software for data analysis.  If your work uses DataJoint or DataJoint Elements, please cite the respective manuscripts and RRIDs.</p>"},{"location":"projects/publications/#2025","title":"2025","text":"<ul> <li>Ding, Z., Fahey, P.G., Papadopoulos, S., Wang, E.Y., Celii, B., Papadopoulos, C., Chang, A., Kunin, A.B., Tran, D., Fu, J. ... &amp; Tolias, A. S. (2025). Functional connectomics reveals general wiring rule in mouse visual cortex. Nature, 640(8058), 459-469.</li> </ul>"},{"location":"projects/publications/#2024","title":"2024","text":"<ul> <li>Reimer, M. L., Kauer, S. D., Benson, C. A., King, J. F., Patwa, S., Feng, S., Estacion, M. A., Bangalore, L., Waxman, S. G., &amp; Tan, A. M. (2024). A FAIR, open-source virtual reality platform for dendritic spine analysis. Patterns, 5(9). Patterns, 5(9).</li> </ul> <ul> <li>Gillon, C. J., Baker, C., Ly, R., Balzani, E., Brunton, B. W., Schottdorf, M., Ghosh, S., &amp; Dehghani, N. (2024). Open Data In Neurophysiology: Advancements, Solutions &amp; Challenges. ArXiv, arXiv:2407.00976v1.</li> </ul> <ul> <li>Mosberger, A.C., Sibener, L.J., Chen, T.X., Rodrigues, H.F., Hormigo, R., Ingram, J.N., Athalye, V.R., Tabachnik, T., Wolpert, D.M., Murray, J.M. and Costa, R.M., 2024. Exploration biases forelimb reaching strategies. Cell Reports, 43(4).</li> </ul> <ul> <li>Guidera, J. A., Gramling, D. P., Comrie, A. E., Joshi, A., Denovellis, E. L., Lee, K. H., ... &amp; Frank, L. M. (2024). Regional specialization manifests in the reliability of neural population codes. bioRxiv, 2024-01.</li> </ul> <ul> <li>Lee, K. H., Denovellis, E. L., Ly, R., Magland, J., Soules, J., Comrie, A. E., Gramling, D. P., Guidera, J. A., Nevers, R., Adenekan, P., Brozdowski, C., Bray, S. R., Monroe, E., Bak, J. H., Coulter, M. E., Sun, X., Broyles, E., Shin, D., Chiang, S., Holobetz, C., \u2026 Frank, L. M. (2024).Spyglass: a framework for reproducible and shareable neuroscience research bioRxiv 2024.01.25.577295</li> </ul> <ul> <li>Chen, S., Liu, Y., Wang, Z. A., Colonell, J., Liu, L. D., Hou, H., ... &amp; Svoboda, K. (2024). Brain-wide neural activity underlying memory-guided movement. Cell, 187(3), 676-691.</li> </ul> <ul> <li>Gonzalo Cogno, S., Obenhaus, H. A., Lautrup, A., Jacobsen, R. I., Clopath, C., Andersson, S. O., ... &amp; Moser, E. I. (2024). Minute-scale oscillatory sequences in medial entorhinal cortex. Nature, 625(7994), 338-344.</li> </ul> <ul> <li>Cimorelli, A., Patel, A., Karakostas, T., &amp; Cotton, R. J. (2024). Validation of portable in-clinic video-based gait analysis for prosthesis users. Nature Scientific Reports, 14(1), 3840.</li> </ul> <ul> <li>Papadopouli, M., Koniotakis, E., Smyrnakis, I., Savaglio, M. A., Psilou, E., Brozi, C., ... &amp; Smirnakis, S. M. (2024). Brain orchestra under spontaneous conditions: Identifying communication modules from the functional architecture of area V1. bioRxiv, 2024-02.</li> </ul>"},{"location":"projects/publications/#2023","title":"2023","text":"<ul> <li>Celii, B., Papadopoulos, S., Ding, Z., Fahey, P. G., Wang, E., Papadopoulos, C., ... &amp; Reimer, J. (2023). NEURD: automated proofreading and feature extraction for connectomics.. bioRxiv. 2023-03.</li> </ul> <ul> <li>Chen, S., Liu, Y., Wang, Z., Colonell, J., Liu, L. D., Hou, H., ... &amp; Svoboda, K. (2023). Brain-wide neural activity underlying memory-guided movement. bioRxiv. 2023-03.</li> </ul> <ul> <li>Cotton, R. J., Cimorelli, A., Shah, K., Anarwala, S., Uhlrich, S., &amp; Karakostas, T. (2023). Improved Trajectory Reconstruction for Markerless Pose Estimation. arXiv. 2303.02413.</li> </ul> <ul> <li>Ding, Z., Fahey, P. G., Papadopoulos, S., Wang, E., Celii, B., Papadopoulos, C., ... &amp; Tolias, A. S. (2023). Functional connectomics reveals general wiring rule in mouse visual cortex. bioRxiv, 2023-03.</li> </ul> <ul> <li>Laboratory, I. B., Bonacchi, N., Chapuis, G. A., Churchland, A. K., DeWitt, E. E., Faulkner, M., ... &amp; Wells, M. J. (2023). A modular architecture for organizing, processing and sharing neurophysiology data. Nature Methods. 1-5.</li> </ul>"},{"location":"projects/publications/#2022","title":"2022","text":"<ul> <li>Wang, Y., Chiola, S., Yang, G., Russell, C., Armstrong, C. J., Wu, Y., ... &amp; Shcheglovitov, A. (2022). Modeling human telencephalic development and autism-associated SHANK3 deficiency using organoids generated from single neural rosettes. Nature Communications, 13(1), 1-25.</li> </ul> <ul> <li>Franke, K., Willeke, K. F., Ponder, K., Galdamez, M., Zhou, N., Muhammad, T., ... &amp; Tolias, A. S. (2022). State-dependent pupil dilation rapidly shifts visual feature selectivity. Nature, 1-7.</li> </ul> <ul> <li>Pettit, N. H., Yap, E., Greenberg, M. E., Harvey, C. D. (2022). Fos ensembles encode and shape stable spatial maps in the hippocampus. Nature.</li> </ul> <ul> <li>Saunders, J. L., Ott, L. A., Wehr, M. (2022). AUTOPILOT: Automating experiments with lots of Raspberry Pis. bioRxiv.</li> </ul> <ul> <li>Born, G. (2022). The effect of feedback on sensory processing in the mouse early visual system. Doctoral dissertation.</li> </ul> <ul> <li>Cobos, E., Muhammad, T., Fahey, P. G., Ding, Z., Ding, Z., Reimer, J., ... &amp; Tolias, A. (2022). It takes neurons to understand neurons: Digital twins of visual cortex synthesize neural metamers. bioRxiv, 2022-12.</li> </ul> <ul> <li>Cadena, S. A., Willeke, K. F., Restivo, K., Denfield, G., Sinz, F. H., Bethge, M., ... &amp; Ecker, A. S. (2022). Diverse task-driven modeling of macaque V4 reveals functional specialization towards semantic tasks. bioRxiv.</li> </ul> <ul> <li>Cotton, R. J. (2022). PosePipe: Open-Source Human Pose Estimation Pipeline for Clinical Research. arXiv. 2203.08792.</li> </ul> <ul> <li>Cotton, R. J., McClerklin, E., Cimorelli, A., &amp; Patel, A. (2022). Spatiotemporal characterization of gait from monocular videos with transformers.</li> </ul> <ul> <li>Cotton, R. J., McClerklin, E., Cimorelli, A., Patel, A., &amp; Karakostas, T. (2022). Transforming Gait: Video-Based Spatiotemporal Gait Analysis. arXiv. 2203.09371.</li> </ul> <ul> <li>Fu, J., Willeke, K. F., Pierzchlewicz, P. A., Muhammad, T., Denfield, G. H., Sinz, F. H., &amp; Tolias, A. S. (2022). Heterogeneous Orientation Tuning Across Sub-Regions of Receptive Fields of V1 Neurons in Mice. Available at SSRN 4029075.</li> </ul> <ul> <li>Zong, W., Obenhaus, H.A., Skyt\u00f8en, E.R., Eneqvist, H., de Jong, N.L., Vale, R., Jorge, M.R., Moser, M.B. and Moser, E.I., 2022. Large-scale two-photon calcium imaging in freely moving mice(:target=\"_blank\"}. Cell, 185(7), pp.1240-1256.</li> </ul> <ul> <li>Goetz, J., Jessen, Z. F., Jacobi, A., Mani, A., Cooler, S., Greer, D., ... &amp; Schwartz, G. W. (2022). Unified classification of mouse retinal ganglion cells using function, morphology, and gene expression. Cell reports, 40(2), 111040.</li> </ul> <ul> <li>Huang, J. Y., Hess, M., Bajpai, A., Barton, S. J., Li, X., Hobson, L. N., &amp; Lu, H. C.   (2022). Sex-and GABAergic-modulated neuronal subnetwork assemblies in   the developing somatosensory cortex. bioRxiv, 2022-10.</li> </ul> <ul> <li>Jaffe, A. (2022). Optical investigation of microcircuit computations in mouse primary visual cortex. Doctoral dissertation.</li> </ul> <ul> <li>Obenhaus, H.A., Zong, W., Jacobsen, R.I., Rose, T., Donato, F., Chen, L., Cheng, H., Bonhoeffer, T., Moser, M.B. &amp; Moser, E.I. (2022). Functional network topography of the medial entorhinal cortex. Proceedings of the National Academy of Sciences, 119 (7).</li> </ul> <ul> <li>Roukes, M. L. (2022, May). The Integrated Neurophotonics Paradigm. In CLEO: Applications and Technology (pp. ATh4I-6). Optica Publishing Group.</li> </ul> <ul> <li>Sanchez, M., Moore, D., Johnson, E. C., Wester, B., Lichtman, J. W., &amp; Gray-Roncal, W. (2022). Connectomics Annotation Metadata Standardization for Increased Accessibility and Queryability. Frontiers in Neuroinformatics.</li> </ul> <ul> <li>Spacek, M. A., Crombie, D., Bauer, Y., Born, G., Liu, X., Katzner, S., &amp; Busse, L. (2022). Robust effects of corticothalamic feedback and behavioral state on movie responses in mouse dLGN. Elife, 11, e70469.</li> </ul> <ul> <li>Tseng, S. Y., Chettih, S. N., Arlt, C., Barroso-Luque, R., &amp; Harvey, C. D. (2022). Shared and specialized coding across posterior cortical areas for dynamic navigation decisions. Neuron.</li> </ul> <ul> <li>Turner, N. L., Macrina, T., Bae, J. A., Yang, R., Wilson, A. M., Schneider-Mizell, C., ... &amp; Seung, H. S. (2022). Reconstruction of neocortex: Organelles, compartments, cells, circuits, and activity. Cell, 185(6), 1082-1100.</li> </ul> <ul> <li>Ustyuzhaninov, I., Burg, M.F., Cadena, S.A., Fu, J., Muhammad, T., Ponder, K., Froudarakis, E., Ding, Z., Bethge, M., Tolias, A. &amp; Ecker, A.S. (2022). Digital twin reveals combinatorial code of non-linear computations in the mouse primary visual cortex. bioRxiv.</li> </ul> <ul> <li>Willeke, K. F., Fahey, P. G., Bashiri, M., Pede, L., Burg, M. F., Blessing, C., ... &amp; Sinz, F. H. (2022). The Sensorium competition on predicting large-scale mouse primary visual cortex activity. arXiv preprint arXiv:2206.08666.</li> </ul>"},{"location":"projects/publications/#2021","title":"2021","text":"<ul> <li>Bae, J. A., Baptiste, M., Bodor, A. L., Brittain, D., Buchanan, J., Bumbarger, D. J., Castro, M. A., Celii, B., Cobos, E., Collman, F., ... (2021). Functional connectomics spanning multiple areas of mouse visual cortex. bioRxiv.</li> </ul> <ul> <li>Born, G., Schneider-Soupiadis, F. A., Erisken, S., Vaiceliunaite, A., Lao, C. L., Mobarhan, M. H., Spacek, M. A., Einevoll, G. T., &amp; Busse, L. (2021). Corticothalamic feedback sculpts visual spatial integration in mouse thalamus. Nature Neuroscience, 24(12), 1711\u20131720.</li> </ul> <ul> <li>Burg, M. F., Cadena, S. A., Denfield, G. H., Walker, E. Y., Tolias, A. S., Bethge, M., &amp; Ecker, A. S. (2021). Learning divisive normalization in primary visual cortex. PLOS Computational Biology, 17(6), e1009028.</li> </ul> <ul> <li>Claudi, F., Campagner, D., &amp; Branco, T. (2021). Innate heuristics and fast learning support escape route selection in mice. bioRxiv.</li> </ul> <ul> <li>Cohrs, K.H. (2021). Investigation of feedback mechanisms in visual cortex using deep learning models. Master\u2019s thesis. University of G\u00f6ttingen.</li> </ul> <ul> <li>Dennis, E. J., El Hady, A., Michaiel, A., Clemens, A., Tervo, D. R. G., Voigts, J., &amp; Datta, S. R. (2021). Systems neuroscience of natural behaviors in rodents. Journal of Neuroscience, 41(5), 911-919.</li> </ul> <ul> <li>Finkelstein, A., Fontolan, L., Economo, M. N., Li, N., Romani, S., &amp; Svoboda, K. (2021). Attractor dynamics gate cortical information flow during decision-making. Nature Neuroscience. 24(6), 843-850.</li> </ul> <ul> <li>Franke, K., Willeke, K. F., Ponder, K., Galdamez, M., Muhammad, T., Patel, S., Froudarakis, E., Reimer, J., Sinz, F., &amp; Tolias, A. (2021). Behavioral state tunes mouse vision to ethological features through pupil dilation. bioRxiv.</li> </ul> <ul> <li>Jacobsen, R. I., Nair, R. R., Obenhaus, H. A., Donato, F., Slettmoen, T., Moser, M.-B., &amp; Moser, E. I. (2021). All-viral tracing of monosynaptic inputs to single birthdate-defined neurons in the intact brain. bioRxiv.</li> </ul> <ul> <li>Laboratory, T. I. B., Aguillon-Rodriguez, V., Angelaki, D., Bayer, H., Bonacchi, N., Carandini, M., Cazettes, F., Chapuis, G., Churchland, A. K., Dan, Y., ... (2021). Standardized and reproducible measurement of decision-making in mice. eLife, 10.</li> </ul> <ul> <li>Strauss, S., Korympidou, M. M., Ran, Y., Franke, K., Schubert, T., Baden, T., Berens, P., Euler, T., &amp; Vlasits, A. L. (2021). Center-surround interactions underlie bipolar cell motion sensing in the mouse retina. bioRxiv.</li> </ul> <ul> <li>Subramaniyan, M., Manivannan, S., Chelur, V., Tsetsenis, T., Jiang, E., &amp; Dani, J. A. (2021). Fear conditioning potentiates the hippocampal CA1 commissural pathway in vivo and increases awake phase sleep. Hippocampus, 31(10), 1154\u20131175.</li> </ul> <ul> <li>Urai, A. E., Aguillon-Rodriguez, V., Laranjeira, I. C., Cazettes, F., Laboratory, T. I. B., Mainen, Z. F., &amp; Churchland, A. K. (2021). Citric acid water as an alternative to water restriction for high-yield mouse behavior. Eneuro, 8(1).</li> </ul> <ul> <li>Wal, A., Klein, F. J., Born, G., Busse, L., &amp; Katzner, S. (2021). Evaluating visual cues modulates their representation in mouse visual and cingulate cortex. Journal of Neuroscience, 41(15), 3531\u20133544.</li> </ul> <ul> <li>Wang, Y., Chiola, S., Yang, G., Russell, C., Armstrong, C. J., Wu, Y., Spampanato, J., Tarboton, P., Chang, A. N., Harmin, D. A., ... (2021). Modeling autism-associated SHANK3 deficiency using human cortico-striatal organoids generated from single neural rosettes. bioRxiv.</li> </ul>"},{"location":"projects/publications/#2020","title":"2020","text":"<ul> <li>Angelaki, D. E., Ng, J., Abrego, A. M., Cham, H. X., Asprodini, E. K., Dickman, J. D., &amp; Laurens, J. (2020). A gravity-based three-dimensional compass in the mouse brain. Nature Communications, 11(1), 1\u201313.</li> </ul> <ul> <li>Cotton, R. J., Sinz, F. H., &amp; Tolias, A. S. (2020). Factorized neural processes for neural processes: K-shot prediction of neural responses. arXiv Preprint arXiv:2010.11810.</li> </ul> <ul> <li>Heath, S. L., Christenson, M. P., Oriol, E., Saavedra-Weisenhaus, M., Kohn, J. R., &amp; Behnia, R. (2020). Circuit mechanisms underlying chromatic encoding in drosophila photoreceptors. Current Biology.</li> </ul> <ul> <li>Laturnus, S., Kobak, D., &amp; Berens, P. (2020). A systematic evaluation of interneuron morphology representations for cell type discrimination. Neuroinformatics, 18(4), 591\u2013609.</li> </ul> <ul> <li>Sinz, F. H., Sachgau, C., Henninger, J., Benda, J., &amp; Grewe, J. (2020). Simultaneous spike-time locking to multiple frequencies. Journal of Neurophysiology, 123(6), 2355\u20132372.</li> </ul> <ul> <li>Yatsenko, D., Moreaux, L. C., Choi, J., Tolias, A., Shepard, K. L., &amp; Roukes, M. L. (2020). Signal separability in integrated neurophotonics. bioRxiv.</li> </ul> <ul> <li>Zhao, Z., Klindt, D. A., Chagas, A. M., Szatko, K. P., Rogerson, L., Protti, D. A., Behrens, C., Dalkara, D., Schubert, T., Bethge, M., others. (2020). The temporal structure of the inner retina at a single glance. Scientific Reports, 10(1), 1\u201317.</li> </ul>"},{"location":"projects/publications/#2019","title":"2019","text":"<ul> <li>Cadena, S. A., Denfield, G. H., Walker, E. Y., Gatys, L. A., Tolias, A. S., Bethge, M., &amp; Ecker, A. S. (2019). Deep convolutional models improve predictions of macaque V1 responses to natural images. PLoS Computational Biology, 15(4), e1006897.</li> </ul> <ul> <li>Chettih, S. N., &amp; Harvey, C. D. (2019). Single-neuron perturbations reveal feature-specific competition in V1. Nature, 567(7748), 334\u2013340.</li> </ul> <ul> <li>Fahey, P. G., Muhammad, T., Smith, C., Froudarakis, E., Cobos, E., Fu, J., Walker, E. Y., Yatsenko, D., Sinz, F. H., Reimer, J., ... (2019). A global map of orientation tuning in mouse visual cortex. bioRxiv, 745323.</li> </ul> <ul> <li>Laurens, J., Abrego, A., Cham, H., Popeney, B., Yu, Y., Rotem, N., Aarse, J., Asprodini, E. K., Dickman, J. D., &amp; Angelaki, D. E. (2019). Multiplexed code of navigation variables in anterior limbic areas. bioRxiv, 684464.</li> </ul> <ul> <li>Liu, G., Froudarakis, E., Patel, J. M., Kochukov, M. Y., Pekarek, B., Hunt, P. J., Patel, M., Ung, K., Fu, C.-H., Jo, J., ... (2019). Target specific functions of EPL interneurons in olfactory circuits. Nature Communications, 10(1), 1\u201314.</li> </ul> <ul> <li>Ros\u00f3n, M. R., Bauer, Y., Kotkat, A. H., Berens, P., Euler, T., &amp; Busse, L. (2019). Mouse dLGN receives functional input from a diverse population of retinal ganglion cells with limited convergence. Neuron, 102(2), 462\u2013476.</li> </ul> <ul> <li>Walker, E. Y., Sinz, F. H., Cobos, E., Muhammad, T., Froudarakis, E., Fahey, P. G., Ecker, A. S., Reimer, J., Pitkow, X., &amp; Tolias, A. S. (2019). Inception loops discover what excites neurons most using deep predictive models. Nature Neuroscience, 22(12), 2060\u20132065.</li> </ul>"},{"location":"projects/publications/#2018","title":"2018","text":"<ul> <li>Denfield, G. H., Ecker, A. S., Shinn, T. J., Bethge, M., &amp; Tolias, A. S. (2018). Attentional fluctuations induce shared variability in macaque primary visual cortex. Nature Communications, 9(1), 2654.</li> </ul> <ul> <li>Ecker, A. S., Sinz, F. H., Froudarakis, E., Fahey, P. G., Cadena, S. A., Walker, E. Y., Cobos, E., Reimer, J., Tolias, A. S., &amp; Bethge, M. (2018). A rotation-equivariant convolutional neural network model of primary visual cortex. arXiv Preprint arXiv:1809.10504.</li> </ul> <ul> <li>Sinz, F., Ecker, A. S., Fahey, P., Walker, E., Cobos, E., Froudarakis, E., Yatsenko, D., Pitkow, Z., Reimer, J., &amp; Tolias, A. (2018). Stimulus domain transfer in recurrent models for large scale cortical population prediction on video. Advances in Neural Information Processing Systems, 7199\u20137210.</li> </ul> <ul> <li>Walker, E. Y., Sinz, F. H., Froudarakis, E., Fahey, P. G., Muhammad, T., Ecker, A. S., Cobos, E., Reimer, J., Pitkow, X., &amp; Tolias, A. S. (2018). Inception in visual cortex: In vivo-silico loops reveal most exciting images. bioRxiv, 506956.</li> </ul>"},{"location":"projects/publications/#2017","title":"2017","text":"<ul> <li>Franke, K., Berens, P., Schubert, T., Bethge, M., Euler, T., &amp; Baden, T. (2017). Inhibition decorrelates visual feature representations in the inner retina. Nature, 542(7642), 439.</li> </ul> <ul> <li>Jurjut, O., Georgieva, P., Busse, L., &amp; Katzner, S. (2017). Learning enhances sensory processing in mouse V1 before improving behavior. Journal of Neuroscience, 37(27), 6460\u20136474.</li> </ul> <ul> <li>Shan, K. Q., Lubenov, E. V., &amp; Siapas, A. G. (2017). Model-based spike sorting with a mixture of drifting t-distributions. Journal of Neuroscience Methods, 288, 82\u201398.</li> </ul>"},{"location":"projects/publications/#2016","title":"2016","text":"<ul> <li>Baden, T., Berens, P., Franke, K., Ros\u00f3n, M. R., Bethge, M., &amp; Euler, T. (2016). The functional diversity of retinal ganglion cells in the mouse. Nature, 529(7586), 345\u2013350.</li> </ul> <ul> <li>Cadwell, C. R., Palasantza, A., Jiang, X., Berens, P., Deng, Q., Yilmaz, M., Reimer, J., Shen, S., Bethge, M., Tolias, K. F., others. (2016). Electrophysiological, transcriptomic and morphologic profiling of single neurons using patch-seq. Nature Biotechnology, 34(2), 199\u2013203.</li> </ul> <ul> <li>Hartmann, L., Drewe-Bo\u00df, P., Wie\u00dfner, T., Wagner, G., Geue, S., Lee, H.-C., Oberm\u00fcller, D. M., Kahles, A., Behr, J., Sinz, F. H., ... (2016). Alternative splicing substantially diversifies the transcriptome during early photomorphogenesis and correlates with the energy availability in arabidopsis. The Plant Cell, 28(11), 2715\u20132734.</li> </ul> <ul> <li>Khastkhodaei, Z., Jurjut, O., Katzner, S., &amp; Busse, L. (2016). Mice can use second-order, contrast-modulated stimuli to guide visual perception. Journal of Neuroscience, 36(16), 4457\u20134469.</li> </ul> <ul> <li>Reimer, J., McGinley, M. J., Liu, Y., Rodenkirch, C., Wang, Q., McCormick, D. A., &amp; Tolias, A. S. (2016). Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex. Nature Communications, 7, 13289.</li> </ul> <ul> <li>Shan, K. Q., Lubenov, E. V., Papadopoulou, M., &amp; Siapas, A. G. (2016). Spatial tuning and brain state account for dorsal hippocampal CA1 activity in a non-spatial learning task. eLife, 5, e14321.</li> </ul>"},{"location":"projects/publications/#2015","title":"2015","text":"<ul> <li>Jiang, X., Shen, S., Cadwell, C. R., Berens, P., Sinz, F., Ecker, A. S., Patel, S., &amp; Tolias, A. S. (2015). Principles of connectivity among morphologically defined cell types in adult neocortex. Science, 350(6264), aac9462.</li> </ul> <ul> <li>Yatsenko, D., Josi\u0107, K., Ecker, A. S., Froudarakis, E., Cotton, R. J., &amp; Tolias, A. S. (2015). Improved estimation and interpretation of correlations in neural circuits. PLoS Comput Biol, 11(3), e1004083.</li> </ul>"},{"location":"projects/publications/#2014","title":"2014","text":"<ul> <li>Ecker, A. S., Berens, P., Cotton, R. J., Subramaniyan, M., Denfield, G. H., Cadwell, C. R., Smirnakis, S. M., Bethge, M., &amp; Tolias, A. S. (2014). State dependence of noise correlations in macaque primary visual cortex. Neuron, 82(1), 235\u2013248.</li> </ul> <ul> <li>Erisken, S., Vaiceliunaite, A., Jurjut, O., Fiorini, M., Katzner, S., &amp; Busse, L. (2014). Effects of locomotion extend throughout the mouse early visual system. Current Biology, 24(24), 2899\u20132907.</li> </ul> <ul> <li>Froudarakis, E., Berens, P., Ecker, A. S., Cotton, R. J., Sinz, F. H., Yatsenko, D., Saggau, P., Bethge, M., &amp; Tolias, A. S. (2014). Population code in mouse V1 facilitates readout of natural scenes through increased sparseness. Nat Neurosci, 17(6), 851\u2013857.</li> </ul> <ul> <li>Reimer, J., Froudarakis, E., Cadwell, C. R., Yatsenko, D., Denfield, G. H., &amp; Tolias, A. S. (2014). Pupil fluctuations track fast switching of cortical states during quiet wakefulness. Neuron, 84(2), 355\u2013362.</li> </ul>"},{"location":"projects/publications/#2013","title":"2013","text":"<ul> <li>Cotton, R. J., Froudarakis, E., Storer, P., Saggau, P., &amp; Tolias, A. S. (2013). Three-dimensional mapping of microcircuit correlation structure. Frontiers in Neural Circuits, 7, 151.</li> </ul> <ul> <li>Vaiceliunaite, A., Erisken, S., Franzen, F., Katzner, S., &amp; Busse, L. (2013). Spatial integration in mouse primary visual cortex. Journal of Neurophysiology, 110(4), 964\u2013972.</li> </ul>"},{"location":"projects/teams/","title":"Teams","text":""},{"location":"projects/teams/#projects","title":"Projects","text":"<p>DataJoint was originally developed by working systems neuroscientists at Baylor College of Medicine to meet the needs of their own research. Below is a partial list of known teams who use DataJoint.</p>"},{"location":"projects/teams/#multi-lab-collaboratives","title":"Multi-lab collaboratives","text":"<ul> <li>International Brain Lab (GitHub)</li> <li>Mesoscale Activity Project</li> <li>MICrONS</li> <li>Sainsbury Wellcome Centre Aeon</li> <li>U19 Projects<ul> <li>NYU Osmonauts</li> <li>Harvard DOPE</li> <li>Columbia MoC3</li> <li>Princeton BRAIN CoGS (GitHub)</li> <li>Rochester-NYU-Harvard Neural basis of causal inference</li> </ul> </li> </ul>"},{"location":"projects/teams/#individual-labs-and-researchers","title":"Individual Labs and Researchers","text":"<ul> <li>Allen Institute<ul> <li>Mindscope Program</li> <li>Karel Svoboda Lab</li> <li>Forrest Collman</li> </ul> </li> <li>Arizona State University<ul> <li>Rick Gerkin Lab</li> </ul> </li> <li>Baylor College of Medicine<ul> <li>Nuo Li Lab</li> <li>Matthew McGinley Lab</li> <li>Paul Pfaffinger Lab</li> <li>Jacob Reimer Lab</li> <li>Andreas Tolias Lab</li> </ul> </li> <li>Boston University<ul> <li>Jerry Chen Lab</li> <li>Benjamin Scott Lab</li> </ul> </li> <li>California Institute of Technology<ul> <li>Roukes Group</li> <li>Siapas Lab</li> </ul> </li> <li>Columbia University's Zuckerman Institute<ul> <li>Mark Churchland Lab</li> <li>Elizabeth Hillman Lab</li> <li>Rui Costa Lab</li> </ul> </li> <li>EPFL<ul> <li>Mackenzie Mathis Lab</li> </ul> </li> <li>FORTH<ul> <li>Emmanouil Froudarakis Lab (GitHub)</li> </ul> </li> <li>Friedrich Miescher Institute for Biomedical Research: FMI<ul> <li> Andreas Luthi Lab </li> </ul> </li> <li>Harvard Medical School<ul> <li>Jan Drugowitsch Lab</li> <li>Datta Lab</li> <li>Harvey Lab</li> <li>Sabatini Lab</li> <li>Stelios Smirnakis Lab</li> </ul> </li> <li>Indiana University<ul> <li>Lu Lab</li> </ul> </li> <li>Janelia Research Campus<ul> <li>Emily Dennis Lab</li> <li>Sue Ann Koay Lab</li> </ul> </li> <li>Johns Hopkins University<ul> <li>Applied Physics Lab (GitHub)</li> <li>Marshall Shuler</li> </ul> </li> <li>Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen<ul> <li>Busse Lab</li> <li>Katzner Lab</li> </ul> </li> <li>MIT<ul> <li>Fan Wang Lab</li> </ul> </li> <li>National Institutes of Health<ul> <li>Eric E. Thomson</li> <li>Joshua Gordon Lab / David Kupferschmidt</li> </ul> </li> <li>New York University<ul> <li>Dora Angelaki Lab</li> </ul> </li> <li>New York University Langone Medical Center<ul> <li>Tanya Sippy Lab</li> </ul> </li> <li>Netherlands Neuroscience Institute <ul> <li>Chris Van Der Togt  (Github) - 7 labs.</li> </ul> </li> </ul> <ul> <li>Northwestern University<ul> <li>James Cotton Lab (GitHub)</li> <li>Gregory Schwartz Lab (GitHub)</li> <li>Lucas Pinto Lab</li> </ul> </li> <li>Princeton University<ul> <li>Carlos Brody Lab</li> <li>David Tank Lab</li> <li>Ilana Witten Lab</li> <li>Tatiana Engel Lab</li> <li>Jonathan Pillow Lab</li> <li>Seung Lab</li> </ul> </li> <li>Norwegian University for Science and Technology - Kavli Institute for Systems Neuroscience <ul> <li>Moser Group</li> <li>Horst Obenhaus</li> </ul> </li> <li>Sainsbury Wellcome Centre<ul> <li>Tiago Branco Lab (GitHub)</li> </ul> </li> <li>Stanford University<ul> <li>Karl Deisseroth Lab</li> <li>Shaul Druckmann Lab</li> </ul> </li> <li>Tel-Aviv University<ul> <li>Arseny Finkelstein Lab (GitHub)</li> <li>Pablo Blinder Lab (GitHub)</li> </ul> </li> <li>IFR-National Center for Biological Sciences, Bengaluru<ul> <li>Abhilasha Joshi</li> </ul> </li> <li>University of Bonn<ul> <li>Tobias Rose Lab</li> <li>Mormann Workgroup</li> </ul> </li> <li>University of California, Los Angeles<ul> <li>Anne Churchland Lab</li> </ul> </li> <li>University of California, San Diego<ul> <li>David Kleinfeld Lab (GitHub)</li> </ul> </li> <li>University of California, San Francisco<ul> <li>Loren Frank Lab</li> <li>Cathryn Cadwell Lab</li> </ul> </li> <li>University of Houston<ul> <li>Lauri Nurminen Lab <li>University of Oregon<ul> <li>Santiago Jaramillo Lab (GitHub)</li> <li>Michael Wehr Lab (GitHub)</li> </ul> </li> <li>University of Pennsylvania School of Medicine<ul> <li>John A. Dani</li> </ul> </li> <li>University of Rochester<ul> <li>Greg DeAngelis Lab</li> <li>Ralf Haefner Lab</li> </ul> </li> <li>Universit\u00e4t T\u00fcbingen<ul> <li>Berens Lab</li> <li>Euler Lab</li> <li>Macke Lab (GitHub)</li> </ul> </li> <li>University of Utah<ul> <li>Oleksandr Shcheglovitov Lab (GitHub)</li> <li>Jan Kubanek Lab</li> </ul> </li> <ul> <li>University of Valencia<ul> <li>Kai-Hendrik Cohrs</li> </ul> </li> </ul> <ul> <li>University of Washington<ul> <li>Edgar Y. Walker Lab</li> <li>Tuthill Lab</li> <li>Anne Gillespie Lab</li> </ul> </li> </ul> <ul> <li>University of Zurich<ul> <li>Fritjof Helmchen Lab</li> </ul> </li> </ul> <ul> <li>Wilhelm Schickard Institute for Computer Science<ul> <li>Sinz Lab</li> <li>Bethge Lab</li> </ul> </li> <li>... and more labs</li> </ul>"}]}